# ml-simple-works

머신 러닝 관련 작은 주제들을 선정해서 jupyter notebook으로 실습을 겸하여 내용을 정리하고 있습니다.

**한국어로 찾아보기 힘든 내용**을 선택하여 가능한 자세하게 풀어적고 있으며 

누구나 쉽게 읽을 수 있도록 작성하고 있습니다.

ipynb 파일은 github에서 직접 보면 수식이 깨지고 예쁘게 나오지 않기 때문에

nbviewer를 통해 보거나 https://metamath1.github.io/ 에서 확인하는 것을 추천합니다.

그리고 PC에서만 보시길 권해드립니다. 모바일에서는 수식이 보기 좋지 않아서......


## 지금까지 정리된 내용

- K 평균 군집화 K-means Clustering, EM/Kmeans.ipynb

- 역전파 알고리즘 완전정복 A Step by Step Backpropagation, BP/bp.ipynb

- 합성곱 신경망에서 컨벌루션과 트랜스포즈드 컨벌루션의 관계 Relationship between Convolution and Transposed Convolution in CNN, CNN/transconv_fullconv.ipynb 

- 서포트벡터머신을 위한 비선형 계획 문제의 쌍대정리Duality in Non-Linear Programming for Support Vector Machine, svm/duality.ipynb 

- 대칭행렬의 대각화와 특잇값 분해Symmetric matrix Diagonalization and Singular Value Decomposition, svd/svd.ipynb

- 벡터, 행렬에 대한 미분Derivatives for vectors and matrices, fitting/matrix-derivative.ipynb

- 다변수 가우시안 확률분포multi-variable normal에서 사전확률분포prior, 사후확률분포posterior, 조건부확률분포conditional와 주변확률분포marginal : Pattern Recognition and Machine Learning - Chap. 2-1 , PRML/prml-chap2.ipynb

- 야코비안Jacobian과 치환적분, sampling/double-integral.ipynb

- 베이즈정리와 정규분포의 곱, fitting/product-of-gaussian.ipynb

- 150줄로 된 간단한 네트워크Simple network with 150 lines, simplenet.ipynb/simplenet.ipynb

- Change of continuous random variable - PRML EX-1.4 보충, GAN/change_of_variable.ipynb

- 나이브 베이즈Naive Bayse - 밑바닥부터 시작하는 데이터 과학Data Science from Scratch 보충 설명, naive/naive.ipynb

- 퍼셉트론 테스트와 수렴정리Perceptron test and its convergence theorem, perceptron/perceptron.ipynb

- GANs 기초 - 엔트로피, Keras로 구현한 1D GANs 그리고 Goodfellow 논문 겉핥기, GAN/GANs.ipynb

- CNN 역전파를 이해하는 가장 쉬운 방법The easiest way to understand CNN backpropagation, https://metamath1.github.io/cnn/index.html
