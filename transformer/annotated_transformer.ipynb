{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"annotated_transformer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNbHSPxgNBpJ/RhZrh3r7Rn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"l-hYvmAnT0J6"},"source":["# 차트에 한글이 나오게끔 한글 폰트 설치\n","!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GUziLQk-tiwn"},"source":["폰트 설치가 끝났으면 런타임을 재시작해서 폰트가 적용되게 하고 다음 셀을 실행하세요."]},{"cell_type":"code","metadata":{"id":"l18LPLlFzaOU"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math, copy, time\n","import matplotlib.pyplot as plt\n","\n","# plt.style.use('dark_background')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkMwlax4UAS-"},"source":["from matplotlib import font_manager, rc\n","\n","# 그래프에 한글 나오는지 확인\n","font_fname = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'     # A font of your choice\n","font_name = font_manager.FontProperties(fname=font_fname).get_name()\n","rc('font', family=font_name)\n","\n","plt.plot(range(50), range(50), 'r')\n","plt.title('가격 추이')\n","plt.ylabel('가격')\n","plt.xlabel('시간(분)')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UQ5YKII2esk4"},"source":["# 진짜로(?) 주석 달린 트랜스포머Really annotated transformers<sup>&#8224;</sup>\n","\n","\n","---\n","\n","2021.11.09 조준우 (metamath@gmail.com), https://metamath1.github.io"]},{"cell_type":"markdown","metadata":{"id":"qO-X1agw9hwO"},"source":["본 글의 원문은 \"The Annotated Transfomer\"[[1](https://nlp.seas.harvard.edu/2018/04/03/attention.html)]로 인터넷에서 참고할 수 있는 트랜스포머에 대한 가장 좋은 문서중 하나입니다. 다른 하나는 \"The Illustrated Transformer\"[[2](https://jalammar.github.io/illustrated-transformer/)], [번역문[3](https://nlpinkorean.github.io/illustrated-transformer/)] 인데 이 문서만 읽어봐도 트랜스포머에 대해서 일부분 이해할 수 있어 꼭 읽어보면 좋은 글입니다. 이 글은 [1]에 대해서 더 풍부하게 주석을 달고 [1]에서 언급되지 않은 부분을 조금 더 상세히 풀어 적은 글입니다.\n","\n","[[1](https://nlp.seas.harvard.edu/2018/04/03/attention.html)]은 논문을 그대로 코드로 옮기고 논문 텍스트와 코드를 함께 제시하기 때문에 공신력 면에서 최고지만 앞서 밝혔듯이 설명이 부족하고 함께 진행하는 코드가 top-down 방식으로 기술되어 있어서 글을 읽기가 힘들다는 단점이 있습니다. 저자들이 이렇게 글을 쓴 이유는 트랜스포머를 발표한 논문 \"Attention is all you need\"[[4](https://arxiv.org/abs/1706.03762)]에서 기술하는 순서를 그대로 지켰기 때문입니다. 코드를 이해시킬 필요없이 전체적인 맥락을 설명하는데는 이런 top-down방식이 더 유리하겠지만 글과 코드를 함께 보는 경우는 좀 다를 수 있습니다. 왜냐하면 top-down 방식으로 제시된 코드 조각에는 필연적으로 아래쪽에서 설명될 예정인 의미를 잘 알 수 없는 인자arguement들이 끊임없이 등장하게 되기 때문입니다. 실제로 [[1](https://nlp.seas.harvard.edu/2018/04/03/attention.html)]을 읽어보면 어느 부분에서 '어? 여기 나온 이 인자가 무엇이지?'라는 생각이 들게 되고 문서 뒤로 가서 궁금한 인자가 등장하는 지점과 연결되는 부분을 찾아보고 다시 앞으로 돌아오기를 계속 반복해야 하는데 몇번 하다보면 지쳐서 글 읽기가 싫어지게 되겠죠.\n","\n","이런 이유때문에 코드와 함께 기술된 글이라면 bottom-up 방식으로 작은 부분부터 이해하면서 점진적으로 큰 부분으로 나가는것이 맞다고 생각합니다. 이 글은 [[1](https://nlp.seas.harvard.edu/2018/04/03/attention.html)]의 코드를 bottom-up 방식으로 재구성하여 읽는 이가 문서를 처음부터 순서대로 읽기만해도 트랜스포머에 대해 편안하게 이해할 수 있도록 하는 것을 목적으로 하고 있습니다.\n","\n","----\n","\n","<sup>&#8224;</sup> 이 글의 제목은 트랜스포머가 가장 강력한 성능을 발휘하는 NMT인 구글 번역기로 번역되었습니다.  ;)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pqrfMxGZ72HW"},"source":["## 트랜스포머를 공부하는 이유\n","\n","트랜스포머는 최근 가장 성공적인 모델임에도 불구하고 CNN, RNN에 대한 사전 지식이 전혀 필요없이 이해할 수 있다는 점에서 입문자분들이 꼭 공부하면 좋을 모델이라고 할 수 있습니다. 트랜스포머를 이해하기 위한 사전 지식은 다음 정도로 정리할 수 있습니다. \n","\n","- 신경망에서 완전 연결층 \n","- 소프트맥스 함수\n","- $\\sin$, $\\cos$ 함수 기초\n","- 데이터를 인코딩해서 다시 디코딩하는 개념\n","- 배치 정규화와 레이어 정규화의 차이\n","- 임베딩 개념\n","- 어텐션 개념\n","\n","앞 네 개 항목은 인공지능에 막 입문한 학습자라도 어느정도 알고 있는 내용이므로 실제로 입문자가 느끼는 추가 학습 부담은 정규화와 임베딩 개념 그리고 가장 핵심인 어텐션이라고 할 수 있습니다. 임베딩에 대해서는 입력을  특정 길이를 가지는 벡터로 바꾼다는 정도만 알아도 전체 내용을 이해하는데 지장이 없습니다. 어텐션에 대해서는 이전 모델인 seq2seq와 그에 대한 어텐션 매커니즘을 알고 있다면 도움이 되지만 몰라도 상관없습니다. \n","\n","이렇게 트랜스포머는 완전 연결층에 대한 기본적인 지식만 가지고 바로 학습할 수 있다는 장점에 더불어 최신 모델들의 근간을 이루는 기본 모델을 공부할 수 있다는 추가 장점도 가지고 있습니다. \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"F5_lwTI8gE0G"},"source":["## 트랜스포머 개요\n","\n","![picture](https://drive.google.com/uc?id=1DudF_35VyVpevpsLr7TfVWi6WeC527kc)\n","Figure 1: The Transformer - model architecture.[[4](https://arxiv.org/abs/1706.03762)]\n","\n","트랜스포머에 대한 그림 중 가장 유명한 그림이 바로 위 그림입니다. 이 그림은 처음 보면 아주 복잡하게 보이지만 트랜스포머를 이해하고 보면 간결하게 모델의 핵심을 잘 설명하고 있다는 것을 알게 됩니다. 이 그림을 통해서 먼저 트랜스포머에 대한 전체 맥락을 알아보겠습니다. 트랜스포머가 적용되는 상황은 기계번역, 즉 입력으로 영어 문장이 들어가서 출력으로 한국어 문장이 나오는 상황을 가정하겠습니다. 그러면 위 그림은 다음과 같은 순서로 데이터가 처리되는 것을 이야기하고 있습니다.\n","\n","1. 입력(Input)이 임베딩 층으로 입력되어 문장의 각 단어들이 적당한 벡터로 변환된다.\n","2. 이 변환된 벡터가 위치 인코딩Positional Encoding이라는 것으로 부터 출력된 단어의 위치 정보를 가지는 벡터와 더해진다.\n","3. 2에서 만들어진 벡터가 멀티 헤드 어텐션Multi-Head Attention이라는 층으로 입력되는데 이 때 같은 입력을 키key, 쿼리query, 벨류value로 넣어준다. \n","4. 멀티 헤드 어텐션 층을 거쳐 출력된 벡터가 멀티 헤드 어텐션 층으로 입력되기 전 벡터와 더해지고(ResNet의 스킵커넥션) 레이어 정규화 된다.\n","5. 4의 출력을 Linear 레이어에 입력하여 출력을 만든다. \n","6. 5의 출력과 4의 출력을 더하고 레이어 정규화 한다. (또 한번 스킵커넥션)\n","7. 6에서 출력된 결과를 입력으로 3으로 돌아가 다시 반복한다. 이렇게 N번 반복한다.\n","\n","여기까지가 트랜스포머의 인코더에 해당되는 내용입니다. 다음은 디코더에 대한 내용입니다.\n","\n","1. 입력과 쌍이 되는 정답을 디코더에 입력한다.\n","2. 인코더와 마찬가지로 정답에 대해서 인코더의 1, 2 과정을 거친다.\n","3. 이렇게 만들어진 벡터를 인코더의 3번, 4번 과정과 동일하게 어텐션한다. 단, 이때 마스크를 씌우게 되는데 이 마스크를 씌우는 부분이 트랜스포머를 이해하는 난관 중 하나입니다. 구체적인 세부 사항은 코드와 함께 설명하겠습니다. 여기서는 일단 어텐션 한다고 생각하면 되겠습니다.\n","4. 3의 출력으로 다시 한번 어텐션하는데 이때는 키, 벨류는 인코더의 출력으로 설정하고 쿼리를 앞 3번 과정의 출력으로 설정하여 어텐션 한다. \n","5. 4의 출력을 입력으로 Linear 레이어를 통과하고 스킵커넥션, 레이어 정규화를 적용한다.\n","6. 5의 출력을 입력으로 3으로 돌아가 다시 반복한다. 이렇게 N번 반복한다.\n","\n","마지막으로 디코더의 내용으로 부터 클래스의 확률을 계산하는 부분은\n","\n","1. 디코더에서 6의 출력을 Linear층으로 입력한다.\n","2. 1의 출력을 Softmax층으로 입력하여 클래스에 대한 확률을 계산한다.\n","\n","이고, 이것이 트랜스포머의 가장 핵심적인 내용입니다. 알고 보면 별것 아닌 내용인데 처음 공부하려면 꽤 복잡해 보이기도 한 것이 사실입니다. \n","\n","여기서 주의해야할 점은 트랜스포머에 입력은 타임스탭별로 하니씩 입력되지 않고 모든 타임스탭의 입력이 동시에 입력되고 출력도 마찬가지라는 점입니다. 예를 들어 다음과 같은 입력이 있을 때\n","\n","`<start>` `I` `don't` `know` `what` `you` `mean` `<end>`\n","\n","입력의 일곱개 단어가 모두 한번에 입력되고 여기에 대한 정답이 다음과 같을 때 \n","\n","`<start>` `나는` `니가` `의미하는` `바를` `모르겠다` `<end>`\n","\n","디코더의 입력으로는\n","\n","`<start>` `나는` `니가` `의미하는` `바를` `모르겠다`\n","\n","이 들어가고 출력으로는 \n","\n","`나는` `니가` `의미하는` `바를` `모르겠다` `<end>`\n","\n","가 나오기를 기대하는 것입니다. 물론 RNN을 사용한 seq2seq같은 모델을 아예 모르는 초심자라면 이런 내용에 주의를 할 필요 조차 없습니다. 그냥 입력이 문장 통째로 들어가서 출력이 문장 통째로 나온다고 생각하면 됩니다.\n","\n","이제 코드를 보면서 그림의 순서대로 따라가봅시다."]},{"cell_type":"markdown","metadata":{"id":"lgX3hWSQRNH3"},"source":["## Embedding"]},{"cell_type":"markdown","metadata":{"id":"TWFwxsoy6WJv"},"source":["트랜스포머에 입력 데이터인 단어를 입력하기 위해서는 단어에 대해 두가지 전처리를 거쳐야 하는데 하나는 임베딩이고 다른 하나는 위치 인코딩입니다. 모델에 단어를 입력할 때 단어를 숫자로 바꿔서 입력하게 되는데 이 때 가급적 목적하는 작업에 도움이 되도록 바꿔야 할 것입니다. 단어-숫자 변환을 최종 작업에 도움이 되는 방향으로 하기 위해 임베딩embedding이라는 층을 사용하게 됩니다. 임베딩 층은 단어를 입력받아 적절한 숫자 벡터로 변환하는 층으로 변환되어 출력되는 벡터의 길이를 코드에서 `d_model`로 표시합니다.\n","\n","임베딩층이 하는 일은 원핫인코딩된 입력벡터를 적절한 밀집벡터로 바꿔주는 것으로 다음처럼 작동합니다.<sup>&#8224;</sup> \n","\n","$$\n","\\mathbf{x}_{\\text{emb}}=\\mathbf{x}W_{\\text{emb}}\n","$$\n","\n","여기서 임베딩 층이 가지는 가중치 행렬 $W_{\\text{emb}}$의 크기는 $(\\text{vocab}, d_{\\text{model}})$이 되고 입력 벡터 $\\mathbf{x}$는 길이가 $(1, \\text{vocab})$인 원핫인코딩된 벡터입니다. 따라서 임베딩 층의 가중치 행렬은 특정 단어에 해당하는 $d_{\\text{model}}$차원의 벡터를 행으로 가지고 있는 룩업 테이블이라고 할 수 있습니다. 다음 그림처럼 단어장에서 단어의 순번을 가지고 변환될 벡터를 찾는 것입니다.\n","\n","![picture](https://drive.google.com/uc?id=1ajCVDKg_c8XQyZFUPr3kuAu3bFRnjAcG)\n","\n","그림을 보면 제일 먼저 'prime'이란 단어를 단어장에서 몇번째 단어인지 찾습니다. 그렇게 찾은 단어의 순번 자리만 1이 되고 나머지는 다 0인 전체 단어 개수만큼 요소를 가지는 원핫벡터를 만듭니다. 이 원핫벡터를 $W_{\\text{emb}}$에 행렬곱해서 임베딩 벡터를 얻는 것입니다.<sup>&#8224;&#8224;</sup>  이렇게 임베딩 층을 거치면 입력이 길이 $d_{\\text{model}}$인 벡터로 변환됩니다.\n","\n","---\n","<sup>&#8224;</sup>  [1]에서는 가중치 행렬 $W$의 행수를 입력, 열수를 출력으로 적고 입력 $\\mathbf{x}$를 행벡터로 하여 $W$ 앞에서 곱하는 방식을 쓰고 있습니다. 다른 표현을 예로 들어보면 파이토치에서는 행벡터와 가중치 행렬의 곱을 $\\mathbf{x} W^{T}$로 표현을 합니다. 여기서 $W$는 행수를 출력, 열수를 입력으로 하고 있는 행렬이 됩니다. 개인적으로 가장 선호하는 방식은 가중치 행렬을 파이토치 형태로 쓰고 열 벡터 $\\mathbf{x}$를 뒤에서 곱하는 $W \\mathbf{x}$ 방식입니다.\n","\n","<sup>&#8224;&#8224;</sup>실제로는 이렇게 행렬곱하지 않습니다. 그냥 $W_{\\text{emb}}$에서 'prime'이라는 단어 인덱스에 해당하는 행을 가져옵니다."]},{"cell_type":"code","metadata":{"id":"ckIXaJBN0AD0"},"source":["class Embeddings(nn.Module):\n","    def __init__(self, d_model, vocab):\n","        super(Embeddings, self).__init__()\n","        self.lut = nn.Embedding(vocab, d_model)\n","        self.d_model = d_model\n","\n","    def forward(self, x):\n","        # 임베딩 벡터에 sqrt(d_model)을 곱해서 임베딩 벡터의 요소들 값을 \n","        # 증가 시킴.\n","        # d_model은 512정도 되는 큰 값이이므로 22정도 되는 값이 \n","        # 임베딩 벡터 요소에 곱해짐. \n","        # 곱하는 이유는 뒤에 포지션 벡터를 더할텐데 이 때 포지션 벡터에\n","        # 의해 임베딩 결과가 희석되는 것을 막기 위함\n","        # ref.: https://stackoverflow.com/questions/56930821/why-does-embedding-vector-multiplied-by-a-constant-in-transformer-model\n","        return self.lut(x) * math.sqrt(self.d_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zxe2mijnWm9e"},"source":["코드는 파이토치 `nn.Embedding`을 그대로 사용합니다. 단 위 코드에서 임베딩 층을 포워드 시킨 결과에 $\\sqrt{d_{\\text{model}}}$을 곱하고 있는 점이 좀 특이합니다. 이렇게 상수를 곱하는 이유는 뒤에 설명할 포지션 벡터가 임베딩 벡터에 더해지는데 이 때 포지션 벡터가 더해지면서 임베딩 벡터의 값이 희석되는 것을 막기 위해 임베딩 벡터의 요소 크기를 상대적으로 크게 하기 위함일 것으로 생각됩니다.[[5](https://stackoverflow.com/questions/56930821/why-does-embedding-vector-multiplied-by-a-constant-in-transformer-model)] 이런 해석은 논문에서 공식적으로 밝히고 있는 것은 아닙니다. 논문에서는 그냥 $\\sqrt{d_{\\text{model}}}$를 곱한다고만 되어 있습니다.\n","\n","이 과정을 거쳐서 길이 $n_{\\text{seq}}$인 입력 문장의 각 단어를 임베딩 벡터로 모두 변환하게 되면 $(n_{\\text{seq}}, d_{\\text{model}})$인 행렬로 변환되게 됩니다."]},{"cell_type":"markdown","metadata":{"id":"QAjuxxn8RUIW"},"source":["## Positional Encoding"]},{"cell_type":"markdown","metadata":{"id":"4fdpGrwUsUCt"},"source":["앞서 이야기한 위치 인코딩입니다. 트랜스포머는 RNN같은 순차적 구조를 사용하지 않고 문장 전체를 한꺼번에 입력하여 문장에 있는 단어간 관계를 특징화하는 모델입니다. RNN은 토큰이 순차적으로 입력되므로 토큰 순서 정보가 자연스럽게 생겨나는 반면 트랜스포머는 토큰의 순서 정보를 인위적으로 만들어 넣어줄 필요가 있습니다. 순서 정보를 인위적으로 만들기위해 논문 저자들은 위치 인코딩이라는 방법을 사용합니다. \n","\n","$$\n","PE_{(pos,2i)}=\\sin \\left( \\frac{pos}{10000^{2i/d_{\\text{model}}}} \\right)\n","$$\n","\n","$$\n","PE_{(pos,2i+1)}=\\cos \\left( \\frac{pos}{10000^{2i/d_{\\text{model}}}} \\right)\n","$$\n","\n","위 식을 사용하여 입력 문장의 위치 정보를 $(n_{\\text{seq}}, d_{\\text{model}})$인 행렬로 인코딩 합니다. 식을 보면 행은 단어의 위치를 나타내는데 단어 위치별 값은 $pos$ 변수에 의해 달라집니다. 열에 대해서는 홀수 열은 $\\cos$함수로 짝수 열은 $\\sin$함수를 사용해서 값을 다르게 계산하는데 열 인덱스 $i$에 대해서 각각 다른 주기(첫 두 열부터 $2 \\pi$ 주기에서 시작해서 마지막 두 열에서는 거의 $10000 \\times 2 \\pi$ 주기를 가짐) 의 삼각함수를 사용하여 모든 열에 대해서 다른 값을 계산하게 됩니다.\n","\n","문장 길이 120에 `d_model=512`인 경우 위치 인코딩을 직접 해보면 다음과 같습니다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"id":"xBewD45hwAnk","executionInfo":{"status":"ok","timestamp":1636599161156,"user_tz":-540,"elapsed":941,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"05f2ee42-9034-4b20-b842-25e13143a806"},"source":["seq_length = 120\n","d_model = 512\n","\n","PE = np.zeros((seq_length, d_model))\n","\n","for pos in range(seq_length):\n","    for i in range(d_model//2):\n","        PE[pos, 2*i]   = np.sin( pos / (10000**(2*i/d_model)) )\n","        PE[pos, 2*i+1] = np.cos( pos / (10000**(2*i/d_model)) )\n","\n","plt.figure(figsize=(6,3))\n","plt.imshow(PE, aspect='auto', cmap='gray', interpolation='gaussian')\n","plt.show()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x216 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"F8EW7-BqBg8y"},"source":["그림으로 표시된 행렬의 각 행은 단어의 위치별로 다르게 계산된 숫자 512개로 구성되어 있고 이 행 벡터가 단어의 위치 정보를 나타내는 고유한 값이 되는 것입니다.\n","\n","논문에서는 위치 인코딩을 어떤 방법으로 해도 상관없다고 이야기합니다. 토큰 위치에 따라 유일하게 다른 값들을 계산해주는 함수라면 뭐든 가능하단 이야기입니다. sin, cos같은 주기 함수를 사용하면 위치에 따라 서로 다른 값을 계산할 수 있는 것 이외에도 상대위치의 선형성을 확보할 수 있다는 장점도 있습니다. 상대위치의 선형성을 자세히 설명한 글은 이 블로그[[6](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)]를 참고하시면 좋겠습니다.\n","\n","여기서는 간단한 실험으로 상대위치의 선형성을 직관적으로 알아보겠습니다."]},{"cell_type":"code","metadata":{"id":"yJFeOstIzeeZ"},"source":["def pe_test(pos, i, d_model=512):\n","    PE = []\n","    PE.append( np.sin( pos / (10000**(2*i/d_model)) ) )\n","    PE.append( np.cos( pos / (10000**(2*i/d_model)) ) )\n","\n","    return np.array(PE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPUOViPw0B6y","executionInfo":{"status":"ok","timestamp":1636599164434,"user_tz":-540,"elapsed":6,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"baea288d-8c75-4136-ccfa-04aa3c5aaeb4"},"source":["k = 10\n","d_model = 512\n","i = 1\n","\n","pos1 = 100\n","pos1k = pos1 + k\n","\n","pos2 = 172\n","pos2k = pos2 + k\n","\n","M_k = np.array([[np.cos(k/(10000**(2*i/d_model))), np.sin(k/(10000**(2*i/d_model)))], \n","                [-np.sin(k/(10000**(2*i/d_model))), np.cos(k/(10000**(2*i/d_model)))]])\n","\n","pe_pos1 = pe_test(pos1, i)\n","pe_pos1k = pe_test(pos1k, i)\n","pe_pos2 = pe_test(pos2, i)\n","pe_pos2k = pe_test(pos2k, i)\n","\n","print(f'pe at {pos1}:', pe_pos1)\n","print(f'pe at {pos1k}:', pe_pos1k)\n","print(f'linear transformation of pe at {pos1} by M:', np.dot(M_k, pe_pos1))\n","\n","print(f'pe at {pos2}:', pe_pos2)\n","print(f'pe at {pos2k}:', pe_pos2k)\n","print(f'linear transformation of pe at {pos2} by M:', np.dot(M_k, pe_pos2))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pe at 100: [ 0.79754236 -0.60326294]\n","pe at 110: [-0.64526647  0.76395758]\n","linear transformation of pe at 100 by M: [-0.64526647  0.76395758]\n","pe at 172: [ 0.55020692 -0.83502835]\n","pe at 182: [-0.3529983   0.93562396]\n","linear transformation of pe at 172 by M: [-0.3529983   0.93562396]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CD2i1Sw69nNl"},"source":["위 소스를 보면 위치 100에서 위치인코딩을 한 값과 `k=10`만큼 떨어진 위치 110에서 위치인코딩 값을 출력합니다. 그리고 위치 100에서 위치 인코딩 값에서 변환형렬 `M_k`을 곱한 값도 함께 출력합니다. 값을 비교해보면 100에서 10만큼 떨어진 위치 110에서 인코딩 값이 100에서 위치 인코딩 값을 M을 사용해 선형변환한 값과 똑같은 것을 알 수 있습니다. 동일한 실험을 기준 위치 172에서 해도 172에서 위치 인코딩 값에 `M_k`을 곱한 갑과 172+10에서 위치 인코딩 값이 동일한 것을 확인할 수 있습니다. 즉 어떤 위치를 기준으로 잡든 `k`(offset)만큼 떨어진 위치에서 인코딩 값은\n","\n","$$\n","PE_{\\text{pos}+k} = M(k) \\times PE_{\\text{pos}}\n","$$\n","\n","라는 선형관계에 있게 되는 것입니다."]},{"cell_type":"markdown","metadata":{"id":"ppsnR1894K0Z"},"source":["위 코드셀에서는 논문에 나온 수식을 그대로 구현하였고 아래 코드에서는 수치 계산에서 안정성을 위해 논문에 식을 그대로 사용하지 않고 아래처럼 변환해서 구현합니다.\n","\n","$$\n","\\begin{aligned}\n","\\frac{pos}{10000^{2i/d_{\\text{model}}}} \n","&= pos \\times \\left[ \\exp\\left\\{{\\log\\left(  \\frac{1}{10000^{2i/d_{\\text{model}}}}\\right)} \\right\\} \\right] \\\\\n","&= pos \\times \\left[ \\exp \\left\\{ \\log \\left( \\left( 10000^{2i/d_{\\text{model}}} \\right)^{-1}  \\right) \\right\\} \\right]\\\\\n","&= pos \\times \\left[ \\exp\\left\\{\\log \\left( 10000^{-2i/d_{\\text{model}}} \\right)\\right\\} \\right] \\\\\n","&= pos \\times \\left[ \\exp\\left\\{ -\\frac{2i}{d_{\\text{model}}} \\log(10000) \\right\\} \\right]\n","\\end{aligned}\n","$$"]},{"cell_type":"code","metadata":{"id":"X-jRt5-U0BXe"},"source":["class PositionalEncoding(nn.Module):\n","    \"Implement the PE function.\"\n","    def __init__(self, d_model, dropout, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        \n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) *\n","                             -(math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","        \n","    def forward(self, x):\n","        pe_val = self.pe[:, :x.size(1)]\n","        pe_val.requires_grad = False\n","        \n","        x = x + pe_val\n","        # x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n","\n","        # page 7\n","        # In addition, we apply dropout to the sums of the embeddings and the\n","        # positional encodings in both the encoder and decoder stacks.\n","        # For the base model, we use a rate of Pdrop=0.1.\n","        return self.dropout(x)\n","        \n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELQTovh2tT9t"},"source":["그리고 마지막 출력을 `nn.Dropout`을 통과시켜 규제regularization 효과를 주고 있습니다.\n","\n","지금까지 설명한 임베딩과 위치 인코딩이 어떻게 작동하는지 실제 간단한 예로 알아보겠습니다. 다음 코드는 열한개 단어를 사용하여 문장을 만들 때 각 단어를 길이 10인 벡터로 임베딩하는 임베딩 층과 이에 대한 위치 인코딩층을 실험한 코드입니다. 코드에 자세한 주석을 달았고 주석을 보면 알 수 있지만 실제 단어로 구성된 문장이 아닌 숫자가 단어라고 가정한 예제입니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"id":"oenqh38-ESNf","executionInfo":{"status":"ok","timestamp":1636599170421,"user_tz":-540,"elapsed":1053,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"a8461e70-8069-4b12-ed27-fc00b486d745"},"source":["torch.random.manual_seed(15)\n","\n","# 단어장 크기 11, 임베딩 벡터 길이 10인 임베딩 층 선언\n","V = 11\n","d_model = 10\n","emb = Embeddings(d_model, V)\n","# 길이 10인 문장의 위치를 인코딩하는 위치 인코딩 층 선언\n","pe  = PositionalEncoding(d_model, 0.1)\n","# 그림 그리기 위해 positional encoding을 복사해둠\n","pe_ = pe.pe.clone()\n","\n","# 문장 길이는 5이고\n","n_seq = 5\n","# 0~10까지 숫자 5개를 무작위로 뽑아서 문장을 구성\n","# 이 예에서 문장은 실제 단어로 구성된 것은 아니고 0, 1, 2, 3, ..., 10인 \n","# 숫자를 단어로 간주함\n","x = torch.randint(0, V-1, (1, n_seq,), requires_grad=False)\n","print(\"integer tokens:\", x)\n","\n","# Feed forward Embeddings-PositionalEncoding\n","# 숫자(단어) 다섯개로 구성된 입력을 임베딩층을 통해 (n_seq, d_model)로 변환\n","embedded = emb(x)\n","\n","# 임베딩 벡터에 대한 위치 인코딩 정보를 구해서 임베딩 벡터에 더함\n","embedded_pe = pe(embedded)\n","\n","# 임베딩 벡터와 위치 인코딩이 더해진 입력 벡터를 그림 \n","fig, axs = plt.subplots(figsize=(18,3), nrows=1, ncols=3)\n","axs[0].imshow(embedded.detach().numpy()[0], aspect='auto', cmap='gray')\n","axs[0].set_xlabel('d_model')\n","axs[0].set_ylabel('n_seq')\n","axs[0].set_title(f\"embedded vector x\")\n","\n","axs[1].imshow(pe_.numpy()[0][:x.shape[1]], aspect='auto', cmap='gray')\n","axs[1].set_xlabel('d_model')\n","axs[1].set_ylabel('n_seq')\n","axs[1].set_title(f\"positional encoding\")\n","\n","axs[2].imshow(embedded_pe.detach().numpy()[0], aspect='auto', cmap='gray')\n","axs[2].set_xlabel('d_model')\n","axs[2].set_ylabel('n_seq')\n","axs[2].set_title(f\"embedded vector x + positional encoding\")\n","\n","plt.show()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["integer tokens: tensor([[8, 4, 6, 8, 1]])\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1296x216 with 3 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"suX7jeqbv4Z2"},"source":["오른쪽 그림을 보면 위치 정보가 임베딩 벡터에 대해져서 원래 임베딩 벡터와는 색이 조금씩 달라진 것을 확인할 수 있습니다. "]},{"cell_type":"markdown","metadata":{"id":"7folB27QqXR6"},"source":["## Encoder\n","\n","이제 인코더로 데이터를 입력하기 위한 준비를 마쳤으니 인코더 구조를 알아봅시다. 글 시작 부분에 제시된 트랜스포머의 그림에서 Multi-Head Attention, Add & Norm 부분을 조금 더 자세히 그리면 아래와 같습니다.\n","\n","![picture](https://drive.google.com/uc?id=10OW0QpQ5jTiW_K__FjmNZphB3fKuSacy)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HCSpqUBUTOWO"},"source":["임베딩과 포지션 인코딩이 끝난 입력이 Q, K, V라는 세 입력으로 인코더로 들어갑니다. 일반적으로 Q(쿼리), K(키), V(벨류)는 다른 값이 되어야 하지만 여기선 셀프 어텐션을 수행하기 때문에 같은 값으로 입력됩니다. 어텐션은 트랜스포머 이전까지 인코더와 디코더 간에 일어나는 연산으로 개발되었으며 셀프 어텐션에 대응되는 용어로 크로스 어텐션이라고 부르기도 합니다. \n"]},{"cell_type":"markdown","metadata":{"id":"_ZLYYG2ktDCk"},"source":["### Attention"]},{"cell_type":"markdown","metadata":{"id":"zOedrrabjOr1"},"source":["\n","어텐션의 기본적인 동작 방식은 쿼리를 가지고 키로 질의를 해서 얻은 어텐션 가중치를 벨류에 적용하는 것입니다. 보통 어텐션에서 키란 인코더에서 생성한 정보로 이 정보를 디코더에게 효율적으로 전달하는 것이 어텐션의 주 목적입니다. 왜냐하면 디코더는 좋은 결과를 생성하기 위해 인코더의 정보를 가능한 많이 활용하는 편이 도움이 되기 때문입니다. 이전 seq2seq는 인코더가 인코딩한 마지막 결과만 디코더로 전달하기 때문에 디코더 입장에서는 좋은 결과를 생성하기 힘든 것이죠. 전체적인 과정은 대략 다음처럼 진행됩니다.\n","\n","1. 인코더는 인코딩 중에 생성된 정보 다시말해 키를 모두 가지고 있습니다.\n","2. 디코더가 정보를 생성할 때 디코더가 만든 중간 결과 즉 쿼리를 가지고 이 쿼리와 가장 관계가 높은 정보가 어떤 것인지 인코더 쪽에 물어 봅니다. \n","3. 인코더는 자기가 인코딩하면서 생성한 정보(키)들 중에 요청받은 쿼리와 어떤 키가 얼마나 적합한지 가중치 계산을 합니다.\n","4. 인코더는 이렇게 계산된 가중치를 디코더로 전달할 벨류라는 값에 가중합하여 디코더로 전달합니다.\n","5. 디코더는 4에서 전달받은 정보와 현재 디코더가 디코딩한 정보를 합하여 최종 결과를 만들어 냅니다.\n","\n","이렇게 크로스 어텐션인 경우 대충 아이디어만 들어도 충분히 성능 향상에 영향을 미치겠다는 생각이 듭니다. 하지만 트랜스포머는 이 어텐션 아이디어를 인코더 또는 디코더에만 적용하는 식으로 적용범위를 넓혔습니다. 인코더는 입력 정보끼리 어텐션을 계산해서 디코더가 디코딩하기 좋은 인코딩 정보를 만들어 낼 수 있고 디코더도 마찬가지로 디코딩되는 정보 끼리 어텐션을 해서 더 좋은 결과를 만들어 낼수 있게 되는 것입니다. 이런 어텐션을 셀프 어텐션이라 합니다.\n","\n","셀프 어텐션은 논문에서 제시하는 다음 수식으로 수행됩니다.\n","\n","$$\n","\\text{Attention}(Q, K, V) = \\text{softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right)V\n","$$\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8IRPp4bJbVGi"},"source":["이렇게 셀프 어텐션이 되면 어떤 점이 좋아지는지 개념을 이해하기 위해 간단한 그림을 보도록 하겠습니다.\n","\n","\n","![picture](https://drive.google.com/uc?id=1c_TAUg5FY3YNknOMKZMW8XGGbwTNGlzF)"]},{"cell_type":"markdown","metadata":{"id":"HDyKVcGSb8wI"},"source":["위 그림은 i love you so much라는 토큰들이 임베딩되는 상황을 나타냅니다. 우선 $W^Q_i$, $W^K_i$, $W^V_i$를 각각 곱하여 $Q$, $K$, $V$를 만들고 그렇게 만들어진 텐서는 색깔을 다르게 표현했습니다. 이후 $\\text{softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right)$가 실행되면 $(n_{\\text{seq}}, n_{\\text{seq}})$인 `p_attn` 행렬이 만들어지는데 이 행렬은 각 토큰들간의 관계가 계산되도록  $W^Q_i$, $W^K_i$가 학습되길 바라는 것입니다.  $W^Q_i$, $W^K_i$가 잘 학습되어 i love you so much라는 문장에서 각 토큰간의 관계가 잘 만들어졌다고 가정하겠습니다. 그러면 love라는 토큰은 한 문장안에서 love, you 라는 토큰하고 관계가 높게 표현될 수 있습니다. 그림에서  `p_attn`을 보면 love에 해당하는 행에서 love와 you에 해당하는 열이 붉게 빛나는 것을 볼 수 있습니다. 이렇게 인코딩된 어텐션 행렬과 $V$를 곱하게 됩니다. 행렬곱은 앞에서 곱하는 행렬의 행으로 뒤에서 곱하는 행렬의 행을 선형조합하는 것과 같습니다. 최종적으로 계산된 `head_i`에서 love에 해당하는 행은 $V$ 행렬의 행 다섯 개가 선형조합된 것인데 이때 $V$에서 love와 you에 해당하는 행에 높은 가중치가 부여되어 조합된 벡터가 됩니다. \n","\n","이렇게 셀프 어텐션되어 출력되는 결과는 각 토큰이 `d_model`사이즈로 변환된 벡터를 가지는데 그치지 않고 각 벡터들이 서로 관계가 높은 토큰들끼리 잘 조합되어 만들어진 벡터가 되게 됩니다."]},{"cell_type":"markdown","metadata":{"id":"ayUe45lhbTjk"},"source":["아래 코드는 어텐션을 구현한 것입니다. 쿼리, 키, 벨류로 무엇을 입력는가에 따라 셀프 어텐션과 크로스 어텐션으로 나눌 수 있으므로 구현 코드는 두 경우 모두 동일합니다.\n"]},{"cell_type":"code","metadata":{"id":"0a6MWdYRz6Hb"},"source":["def attention(query, key, value, mask=None, dropout=None):\n","    \"Compute 'Scaled Dot Product Attention'\"\n","    # 아래서 nbatches는 미니배치 크기, 코드에서 nbatches라는 변수명을 쓰므로\n","    # 표기를 통일하기 위해 nbatches로 표기\n","    # query: (nbatches, h, n_seq, d_k)\n","    # key:   (nbatches, h, n_seq, d_k)\n","    # value: (nbatches, h, n_seq, d_v) 인데 d_k=d_v로 두었음\n","    # 이 함수는 아래쪽 MultiHeadedAttention 클래스의 foward 함수에서 호출됨\n","\n","    d_k = query.size(-1)\n","    \n","    # Scaled에 대한 여러 참고 링크들\n","    # https://stats.stackexchange.com/questions/318243/variance-and-expectation-of-dot-product\n","    # https://www.reddit.com/r/learnmath/comments/9gbk4q/mean_and_variance_of_dot_product_of_two_random/\n","    # https://stats.stackexchange.com/questions/52646/variance-of-product-of-multiple-random-variables\n","    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n","    # scores: (nbatches, h, n_seq, n_seq)\n","    \n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, -1e9)\n","\n","    p_attn = F.softmax(scores, dim = -1)\n","\n","    if dropout is not None:\n","        p_attn = dropout(p_attn)\n","\n","    # torch.matmul(p_attn, value): (nbatches, h, n_seq, n_seq)*(nbatches, h, n_seq, d_v)\n","    # = (nbatches, h, n_seq, d_v),      p_attn: (nbatches, h, n_seq, nseq)\n","    return torch.matmul(p_attn, value), p_attn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"daF4FY2Anpzi"},"source":["위 과정을 Scaled-dot product attention이라고 하는데 $\\sqrt{d_k}$로 나누는 부분 때문에 scaled라는 이름이 붙었습니다. $\\sqrt{d_k}$로 나누는 이유는 softmax를 취한 후 값들이 극단적으로 0과 1이 몰리게 되는 것을 막기 위함입니다. 만약 이런 현상이 일어난다면 softmax를 미분했을 때 미분 계수가 거의 0이 되어 그래디언트를 구하기 힘들어지는 문제가 생깁니다. 좀 더 자세한 설명은 아래 기술하였습니다. \n","\n","바쁘신 분들은 스킵해도 좋겠습니다. 🤨\n","\n","인코더는 N개가 누적되면서 인코더의 출력이 다시 인코더의 입력으로 들어가는 구조로 되어 있습니다. 그림을 보면 인코더가 인코딩을 출력하기 전에 레이어 정규화층을 거치게 됩니다. 즉 셀프 어텐션을 위해 입력되는 $Q$, $K$는 레이어 정규화를 거치게 되므로 $Q$, $K$의 행벡터 $\\mathbf{q}$와 $\\mathbf{k}$의 요소들은 대략적으로 평균 0, 분산 1을 따른다고 가정할 수 있습니다.\n","\n","$$\n","q_i , k_i \\sim p(0, 1)\n","$$\n","\n","행렬곱 $Q K^T$에서 $Q$의 길이 $d_k$인 행벡터 $\\mathbf{q}$와 $K$의 열벡터 $\\mathbf{k}$가 내적되는데 이 때 벡터의 요소가 서로 독립이고 위처럼 평균 0, 분산 1을 따른다고 가정하면 $\\mathbf{q} \\cdot \\mathbf{k}$는 평균 0, 분산 $d_k$를 가지게 됩니다. 이는 다음처럼 보일 수 있습니다.\n","\n","$$\n","\\begin{aligned}\n","\\mathbb{E}\\left[\\mathbf{q} \\cdot \\mathbf{k}\\right] \n","&= \\mathbb{E}\\left[ \\sum_{i=1}^{d_k} q_i k_i \\right] \\\\\n","&= \\sum_{i=1}^{d_k} \\mathbb{E} \\left[ q_i k_i \\right]\n","\\end{aligned} \\tag{1}\n","$$\n","\n","위 식(1)에서 기댓값의 성질 $\\mathbb{E}[X+Y] = \\mathbb{E}[X]+\\mathbb{E}[Y]$가 사용되었습니다. 이제 시그마 안쪽 $\\mathbb{E} \\left[ q_i k_i \\right]$를 전개해보면\n","\n","$$\n","\\begin{aligned}\n","\\mathbb{E}[q_i k_i] \n","&= \\sum_{q_i} \\sum_{k_i} q_i  k_i \\ p(q_i, k_i) \\\\\n","&= \\sum_{q_i} \\sum_{k_i} q_i  k_i \\ p(q_i) p(k_i)  \\quad \\because q_i \\text{ and } k_i \\text{ are independent}  \\\\\n","&= \\sum_{q_i} q_i \\, p(q_i) \\sum_{k_i} k_i \\, p(k_i) \\\\\n","&= \\mathbb{E}[q_i] \\, \\mathbb{E}[k_i] = 0 \\quad \\because \\mathbb{E}[q_i] = \\mathbb{E}[k_i] = 0\n","\\end{aligned} \\tag{2}\n","$$\n","\n","식(2)의 결과를 식(1)에 대입하면 \n","\n","$$\n","\\begin{aligned}\n","\\mathbb{E}\\left[\\mathbf{q} \\cdot \\mathbf{k}\\right] \n","&= \\mathbb{E}\\left[ \\sum_{i=1}^{d_k} q_i k_i \\right] \\\\\n","&= \\sum_{i=1}^{d_k} \\mathbb{E} \\left[ q_i k_i \\right] \\\\\n","&= \\sum_{i=1}^{d_k} 0 = 0\n","\\end{aligned}\n","$$\n","\n","이 되게 됩니다."]},{"cell_type":"markdown","metadata":{"id":"uUr0Ihbhj091"},"source":["분산도 위와 비슷한 과정으로 $d_k$가 됨을 보일 수 있습니다.\n","\n","$$\n","\\begin{aligned}\n","\\text{Var}\\left[\\mathbf{q} \\cdot \\mathbf{k}\\right] \n","&= \\text{Var}\\left[\\sum_{i=1}^{d_k} q_i k_i \\right]  \\\\\n","&= \\sum_{i=1}^{d_k} \\text{Var} \\left[ q_i k_i \\right]\n","\\end{aligned} \\tag{3}\n","$$\n","\n","식(3)에서 독립인 확률변수에 대한 분산의 성질 $\\text{Var}[X+Y] = \\text{Var}[X] + \\text{Var}[Y]$가 사용되었습니다. \n","\n","이제 기댓값처럼 시그마 안쪽을 전개하면\n","\n","$$\n","\\begin{aligned}\n","\\text{Var}\\left[ q_i k_i\\right] \n","&= \\mathbb{E}[q_i^2 k_i^2]-\\left(\\mathbb{E}[q_i k_i ]\\right)^2 \\\\[5pt]\n","&= \\mathbb{E}\\left[q_i^2\\right] \\mathbb{E}\\left[ k_i^2 \\right] - \\mathbb{E}\\left[q_i\\right]^2 \\mathbb{E} [k_i]^2 \\\\[5pt]\n","&=\\left( \\text{Var}[q_i]+\\mathbb{E}[q_i]^2 \\right) \\left( \\text{Var}[k_i]+\\mathbb{E}[k_i]^2 \\right) - \\mathbb{E}\\left[q_i\\right]^2 \\mathbb{E} [k_i]^2 \\\\[5pt]\n","&= \\text{Var}[q_i] \\text{Var}[k_i] + \\text{Var}[q_i] \\mathbb{E} [k_i]^2 + \\mathbb{E} [q_i]^2 \\text{Var}[k_i] + \\mathbb{E}\\left[q_i\\right]^2 \\mathbb{E} [k_i]^2 - \\mathbb{E}\\left[q_i\\right]^2 \\mathbb{E} [k_i]^2 \\\\[5pt]\n","&= \\text{Var}[q_i] \\text{Var}[k_i] + \\text{Var}[q_i] \\mathbb{E} [k_i]^2 + \\mathbb{E} [q_i]^2 \\text{Var}[k_i]\n","\\end{aligned}\n","$$\n","\n","여기서 각 요소들은 $ \\mathbb{E} [q_i] = \\mathbb{E} [k_i] = 0 $ , $\\text{Var}[q_i] = \\text{Var}[k_i] = 1$이므로\n","\n","$$\n","\\text{Var}\\left[ q_i k_i\\right] = \\text{Var}[q_i] \\text{Var}[k_i] = 1 \\tag{4}\n","$$\n","\n","이 되고 식(4)를 윗 식에 대입하면\n","\n","$$\n","\\begin{aligned}\n","\\text{Var}\\left[\\mathbf{q} \\cdot \\mathbf{k}\\right] \n","&= \\text{Var}\\left[\\sum_{i=1}^{d_k} q_i k_i \\right]  \\\\\n","&= \\sum_{i=1}^{d_k} \\text{Var} \\left[ q_i k_i \\right] \\\\\n","&= \\sum_{i=1}^{d_k}  \\text{Var}[q_i] \\text{Var}[k_i] \\\\\n","&= \\sum_{i=1}^{d_k} 1 = d_k\n","\\end{aligned}\n","$$\n","\n","이 됨을 알 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"yYtrEdRMs1AG"},"source":["두 행렬을 곱한 행렬의 요소 $\\left(Q K^T \\right)_{ij}$는 $\\mathbf{q}_i \\cdot \\mathbf{k}_j$로 계산되는데 앞선 계산에서 본것 처럼 분산이 $d_k$가 되므로 $d_k$가 커질 수록 $\\left(Q K^T \\right)_{ij}$의 값들의 차이도 커지게 됩니다. $\\left(Q K^T \\right)_{ij}$들의 분산이 커지면 $ Q K^T  $가 소프트맥스 함수를 거친 후 요소의 값은 1에 아주 가깝거나 0에 아주 가까운 값들로 구성되게 될 것입니다. 한편 소프트맥스 $\\mathbf{s}(\\mathbf{z})$의 미분은 다음과 같습니다.\n","\n","$$\n","\\frac{\\partial}{\\partial z_j} s_i(\\mathbf{z})=\\begin{cases}\n","s_j(\\mathbf{z}) (1-s_j(\\mathbf{z})), & \\mbox{if } i = j \\\\\n","-s_i(\\mathbf{z})s_j(\\mathbf{z}), & \\mbox{if } i \\neq j\n","\\end{cases}\n","$$\n","\n","위 식을 보면 소프트맥스 함수의 미분계수는 결국 소프트맥스 함수의 요소들 끼리 곱으로 결정되는데 이 요소들이 0에 아주 가깝거나 1에 아주 가깝게 되면 미분계수가 매우 작아지는 문제가 생기게 됩니다. 결과적으로 소프트맥스 함수를 백워드 패스할 때 미분계수가 매우 작아져서 학습에 문제가 생기게 되겠죠. 그래서 앞서 구한 $\\left(Q K^T \\right)_{ij}$의 표준편차인 $\\sqrt{d_{\\text{k}}}$로 나눠서 평균과 분산을 0, 1에 가깝게 만들려하는 것입니다. "]},{"cell_type":"markdown","metadata":{"id":"-zv0_nz0t3vk"},"source":["#### Multi-Head Attention\n","\n","앞 절에서 이야기한 어텐션을 한번만 하는 것이 아니라 $h$번하고 그 결과로 나온 $(n_{seq}, d_{v})$인 결과 $h$개를 $d_v$ 방향으로 `concat`시켜 최종적으로 $(n_{seq}, hd_{v})$ 만들게 됩니다. 위 인코더 그림에서 이를 표현하고 있습니다. \n","\n","그리고 이 $(n_{seq}, hd_{v})$를 $(hd_{v}, d_{model})$인 $W^o$와 곱하여 결과를 $(n_{seq}, d_{model})$로 만들게 됩니다. 아래 그 코드가 있는데 매우 교묘하게 코딩되어 있어 주의깊게 볼 필요가 있습니다. 우선 코드에 적혀있는 주석을 읽고 코드를 이해해봅시다.\n"]},{"cell_type":"code","metadata":{"id":"AQTK7gaSzmVa"},"source":["def clones(module, N):\n","    \"Produce N identical layers.\"\n","    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUsjvdDQz8S_"},"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, h, d_model, dropout=0.1):\n","        \"Take in model size and number of heads.\"\n","        super(MultiHeadedAttention, self).__init__()\n","        assert d_model % h == 0\n","        # We assume d_v always equals d_k\n","        self.d_k = d_model // h  # Q, K의 차원\n","        self.h = h\n","        \n","        # Wq, Wk, Wv and Wo\n","        # Wq, Wk, Wv를 각각 h개 만들지 않고 \n","        # Wq, Wk, Wv를 d_model의 1/h 크기로 만듬\n","        self.linears = clones(nn.Linear(d_model, d_model), 4) \n","        \n","        self.attn = None\n","        self.dropout = nn.Dropout(p=dropout)\n","        \n","    def forward(self, query, key, value, mask=None):\n","        # query, key, value: (n_seq, d_model)\n","        \"Implements Figure 2\"\n","        if mask is not None:\n","            # EncoderLayer에서 호출될 때\n","            # mask는 src_mask: (nbatches, 1, n_seq_src)\n","            # DecoderLayer에서 호출될 때\n","            # self_attn으로 호출되면 mask는 tgt_mask: (nbatches, n_seq_trg, n_seq_trg)\n","            # src_attn(cross_attn)으로 호출되며 mask는 src_mask: (nbatches, 1, n_seq_src)\n","            \n","            # Same mask applied to all h heads.\n","            mask = mask.unsqueeze(1)\n","        nbatches = query.size(0)\n","        \n","        # 1) Do all the linear projections in batch from d_model => h x d_k \n","        # self.linears는 요소 네갠데 (query, key, value)와 짝을 맞춰서\n","        # 루프는 총 3번 돌아감\n","        query, key, value = \\\n","            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n","             for l, x in zip(self.linears, (query, key, value))]\n","        # 이 라인이 실행되면 query, key, value는 각각\n","        # (nbatches, h, n_seq, d_k) 가 됨\n","        \n","        # 2) Apply attention on all the projected vectors in batch. \n","        x, self.attn = attention(query, key, value, mask=mask, \n","                                 dropout=self.dropout)\n","        # x: (nbatches, h, n_seq, d_v),  self.attn: (nbatches, h, n_seq, n_seq)\n","\n","        # 3) \"Concat\" using a view and apply a final linear. \n","        x = x.transpose(1, 2).contiguous() \\\n","             .view(nbatches, -1, self.h * self.d_k)\n","        # x: (nbatches, n_seq, h*d_k) 여기서 h*d_k=d_model\n","\n","        # 4) matmul x and Wo -> (nbatches, n_seq, d_model)\n","        return self.linears[-1](x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B_f04zeIo4GD"},"source":["위 코드에서 가장 난해한 코드는 주석 1) 부분입니다. \n","\n","```python\n","# 1) Do all the linear projections in batch from d_model => h x d_k \n","# self.linears는 요소 네갠데 (query, key, value)와 짝을 맞춰서\n","# 루프는 총 3번 돌아감\n","query, key, value = \\\n","    [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n","        for l, x in zip(self.linears, (query, key, value))]\n","# 이 라인이 실행되면 query, key, value는 각각\n","# (nbatches, h, n_seq, d_k) 가 됨\n","```\n","\n","1)에서 $(n_{seq}, d_{k})$ 모양의 쿼리, 키, 벨류 $h$개를 동시에 만들고 있습니다. 쿼리를 만드는 과정을 아래 그림으로 자세히 나타냈습니다. 나머지 키와 벨류에 대해서도 동일한 연산이 수행됩니다.\n","  \n","![picture](https://drive.google.com/uc?id=10JMUOLLUgyPJwqQvVyWG2J9MmUIB_gEo)\n","\n","그림 상단에 코드가 주석 1)에 해당하는 코드이며 코드 부분이 진행되는 순서대로 텐서를 표현하였습니다. 1)에서 결과를 앞서 알아본 `attention` 함수로 입력하여 어텐션 결과와 어텐션 맵을 돌려 받는 부분이 2)입니다. 그런 다음 3)에서 $h$개 어텐션 결과를 `concat`하고 이를 4)에서 $W^O$와 곱하게 됩니다.\n","\n","마지막 완전연결층의 가중치 $W^{O}$는 $(hd_v , d_{\\text{model}})$ 크기를 가지므로 이 층의 입력차원은 $hd_v$, 출력차원은 $d_{\\text{model}}$이 됩니다. 입력으로 들어오는 멀티 헤드 어텐션의 출력은 $(n_{\\text{seq}} , hd_k)$입니다. 셀프 어텐션에서 $d_k=d_v$이므로 마지막 완전연결층을 통과하면 출력은 $(n_{\\text{seq}},d_{\\text{model}})$이 됩니다. \n","\n","위 멀티헤드어텐션 `forward()`에서 마지막 줄입니다.\n","\n","```python\n","# matmul x and Wo -> (nbatches, n_seq, d_model)\n","return self.linears[-1](x)\n","```\n","\n","3)과 4) 과정을 아래 그림으로 나타내었습니다. 인코더의 전체 그림과 함께 비교하면 이해하기가 훨씬 쉬워집니다.\n","\n","![picture](https://drive.google.com/uc?id=10KXLvpL_UU1NbWQT5sTlaiF5EHtQdhek)\n"]},{"cell_type":"markdown","metadata":{"id":"Nqd8GdVgtUTO"},"source":["### Normalization"]},{"cell_type":"markdown","metadata":{"id":"Dd4oK0hZCjKv"},"source":["앞선 단계를 거쳐 얻은 결과는 모양이 $(\\text{nbatches}, n_{\\text{seq}}, d_{\\text{model}})$이고 인코더의 입력도 모양이 $(\\text{nbatches}, n_{\\text{seq}}, d_{\\text{model}})$이므로 서로 요소끼리 더할 수 있습니다. 이렇게 더하는 과정을 스킵커넥션skip-connection이라고 합니다. 스킵 커넥션은 ResNet[[6](https://arxiv.org/abs/1512.03385)]에서 소개된 기법으로 이 후 모델에서는 거의 필수로 사용되는 기법입니다. 이렇게 스킵커넥션까지 거친 텐서를 정규화하게 되는데 여기서는 보편적으로 사용하는 배치정규화를 쓰지 않고 레이어 정규화를 사용합니다. \n","\n","배치 정규화와 레이어 정규화의 차이를 알아보기 위해 구체적인 예를 들어 보겠습니다."]},{"cell_type":"markdown","metadata":{"id":"gkZRxTeu7RwM"},"source":["#### Batch Normalization\n","\n","배치 정규화에 대한 수식은 아래와 같습니다.\n","\n","$$\n","y = \\frac{x - \\mathbb{E}[x]}{\\sqrt{\\text{Var}[x]+\\epsilon}} * \\gamma + \\beta\n","$$\n","\n","식만보면 입력 배치 $x$에 대한 평균과 분산을 구해서 입력들에 대해서 표준화 작업을 하는 것입니다. 그런데 PyTorch 구현체를 보면 상황이 조금 더 복잡합니다.\n","\n","\n","![picture](https://drive.google.com/uc?id=1BdMW-mYOwNea6yH6wyk63ZPCBSsHLGij)\n","\n","위 그림은 데이터 하나가 요소 4개짜리 벡터이고 미니배치 크기가 3인 상황을 나타내었습니다. 이 경우 입력 텐서는 (3,4) 또는 (3,1,4)입니다. 트랜스포머로 입력되는 상황을 고려하면 (3,1,4)가 적합한데 각 차원은 (nbatches, n_seq, embedding)으로 샘플은 세 개, 각 샘플당 토큰은 한 개, 각 토큰은 숫자 네 개로 임베딩되어 있는 상황입니다. 노란색, 주황색, 보라색 데이터가 각각 네트워크에 입력되고 길이 여섯개짜리 벡터로 변환되면 출력은 (3,1,6)이 됩니다.   \n","\n","이 출력에 배치 정규화를 적용하면 `(N, C, L)`에서 `C`에 대해 데이터를 구분해서 `C`별로 평균과 분산을 구하게 됩니다. 이것은 이미지에 대해서 배치 정규화를 적용하면 이미지의 채널별로 평균과 분산을 구하는 것과 동일한 방식입니다.\n","\n","실제로 그렇게 작동하는지 아래 pytorch 코드와 직접 만든 배치 정규화 코드의 결과를 비교하였습니다. \n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWbJcixn8iqt","executionInfo":{"status":"ok","timestamp":1636599183822,"user_tz":-540,"elapsed":262,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"aa515a46-d7f7-45b2-da4a-c530e89bd8f1"},"source":["torch.manual_seed(0)\n","\n","# 배치사이즈 3, 단어 한개로 구성된 문장, feature 4\n","x = torch.randn(3, 1, 4)\n","print('\\nINPUT', x.shape)\n","print(x)\n","\n","# 4차원 벡터를 6차원 벡터로 변환하는 완전연결 층\n","linear = nn.Linear(x.shape[-1], 6)\n","x = linear(x)\n","print('\\nACTIVATION', x.shape)\n","print(x)\n","\n","#===================\n","# batch norm.\n","# pytorch \n","bnorm = nn.BatchNorm1d(x.shape[1], eps=0., momentum=0.)\n","print('\\nPYTORCH BATCH NORM. 1D')\n","print(bnorm(x))\n","\n","# 직접 만들기\n","mean = x.mean(axis=(0,2)).reshape(-1,1)\n","var = x.var(axis=(0,2), unbiased=False).reshape(-1,1)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nMY BATCH NORM.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)\n","#===================\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT torch.Size([3, 1, 4])\n","tensor([[[ 1.5410, -0.2934, -2.1788,  0.5684]],\n","\n","        [[-1.0845, -1.3986,  0.4033,  0.8380]],\n","\n","        [[-0.7193, -0.4033, -0.5966,  0.1820]]])\n","\n","ACTIVATION torch.Size([3, 1, 6])\n","tensor([[[-1.6115,  0.2043,  0.3828, -0.4272, -0.1355, -0.9343]],\n","\n","        [[-0.4144,  0.7838,  0.4598,  0.5056,  0.1713,  1.1928]],\n","\n","        [[-0.5397,  0.4543,  0.7689,  0.4446,  0.1475,  0.2965]]],\n","       grad_fn=<AddBackward0>)\n","\n","PYTORCH BATCH NORM. 1D\n","tensor([[[-2.5974,  0.1627,  0.4341, -0.7971, -0.3537, -1.5679]],\n","\n","        [[-0.7777,  1.0436,  0.5512,  0.6207,  0.1127,  1.6653]],\n","\n","        [[-0.9681,  0.5429,  1.0210,  0.5281,  0.0764,  0.3030]]],\n","       grad_fn=<NativeBatchNormBackward>)\n","\n","MY BATCH NORM.\n","mean shape: torch.Size([1, 1])\n","var shape: torch.Size([1, 1])\n","tensor([[[-2.5974,  0.1627,  0.4341, -0.7971, -0.3537, -1.5679]],\n","\n","        [[-0.7777,  1.0436,  0.5512,  0.6207,  0.1127,  1.6653]],\n","\n","        [[-0.9681,  0.5429,  1.0210,  0.5281,  0.0764,  0.3030]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"H2ekyQ_lieG8"},"source":["두 경우 모두 출력이 동일하고 평균과 분산은 숫자 하나라는 사실을 알 수 있습니다. (이 예에서 C=1이기 때문입니다.)"]},{"cell_type":"markdown","metadata":{"id":"oC8knQQGtzUQ"},"source":["![picture](https://drive.google.com/uc?id=1RBZJ6wWqq5PABCW8Yw5-Ny9yupcxNRqA)\n","\n","이번에는 데이터가 위처럼 입력된다고 생각해봅시다. 이 상황은 샘플 세 개가 입력되는데 전과는 다르게 각 데이터는 토큰이 두 개로 구성된 문장이고 토큰 하나는 숫자 네 개짜리 벡터로 표현된 상황입니다. 이번 예에서는 C=2이기 때문에 각 샘플의 첫번째 단어끼리 평균과 분산을 구하고, 두번째 단어끼리 평균과 분산을 구해서 각 단어에 대해 표준화를 수행할 것입니다.\n","\n","아래 코드를 보면 그 사실을 확인할 수 있습니다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlNATxHvJcbc","executionInfo":{"status":"ok","timestamp":1636599187061,"user_tz":-540,"elapsed":388,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"8e5d3830-3317-4619-8472-20e1bac2fb53"},"source":["# 배치사이즈 3, 단어 두 개로 구성된 문장, feature 4\n","x = torch.randn(3, 2, 4)\n","print('\\nINPUT', x.shape)\n","print(x)\n","\n","# 4차원 벡터를 6차원 벡터로 변환하는 완전연결 층\n","linear = nn.Linear(x.shape[-1], 6)\n","x = linear(x)\n","print('\\nACTIVATION', x.shape)\n","print(x)\n","\n","#===================\n","# batch norm.\n","# pytorch \n","bnorm = nn.BatchNorm1d(x.shape[1], eps=0., momentum=0.)\n","print('\\nPYTORCH BATCH NORM. 1D')\n","print(bnorm(x))\n","\n","# 직접 만들기\n","mean = x.mean(axis=(0,2)).reshape(-1,1)\n","var = x.var(axis=(0,2), unbiased=False).reshape(-1,1)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nMY BATCH NORM.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)\n","#==================="],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT torch.Size([3, 2, 4])\n","tensor([[[ 5.4329e-01, -3.9516e-01,  2.0553e-01, -4.5033e-01],\n","         [-5.7308e-01, -5.5536e-01,  5.9432e-01,  1.5419e+00]],\n","\n","        [[-1.0925e+00, -8.5194e-02, -9.3348e-02,  6.8705e-01],\n","         [-8.3832e-01,  8.9182e-04,  8.4189e-01, -4.0003e-01]],\n","\n","        [[ 6.2114e-01,  6.3818e-01, -2.4600e-01,  2.3025e+00],\n","         [-1.8817e+00, -4.9727e-02, -1.0450e+00, -9.5650e-01]]])\n","\n","ACTIVATION torch.Size([3, 2, 6])\n","tensor([[[-0.0636, -0.0346,  0.0337, -0.0617, -0.7393,  0.5536],\n","         [ 0.8464,  1.3011,  0.0941,  0.5593,  0.2273,  0.2352]],\n","\n","        [[ 0.6898,  0.7568,  0.4834,  0.5283,  0.2946, -0.0747],\n","         [ 0.6558,  0.7065, -0.0185,  0.2920, -0.5097, -0.1648]],\n","\n","        [[-0.2619,  0.3526,  0.0770, -0.2704,  0.9377,  0.2629],\n","         [ 0.6593,  0.0531,  1.1190,  0.7146,  0.0106, -0.2787]]],\n","       grad_fn=<AddBackward0>)\n","\n","PYTORCH BATCH NORM. 1D\n","tensor([[[-0.6198, -0.5497, -0.3845, -0.6153, -2.2559,  0.8745],\n","         [ 1.0204,  1.9767, -0.5619,  0.4166, -0.2817, -0.2651]],\n","\n","        [[ 1.2042,  1.3664,  0.7044,  0.8132,  0.2472, -0.6468],\n","         [ 0.6196,  0.7262, -0.7988, -0.1456, -1.8319, -1.1065]],\n","\n","        [[-1.1000,  0.3878, -0.2796, -1.1207,  1.8043,  0.1706],\n","         [ 0.6268, -0.6482,  1.5938,  0.7432, -0.7376, -1.3461]]],\n","       grad_fn=<NativeBatchNormBackward>)\n","\n","MY BATCH NORM.\n","mean shape: torch.Size([2, 1])\n","var shape: torch.Size([2, 1])\n","tensor([[[-0.6198, -0.5497, -0.3845, -0.6153, -2.2559,  0.8745],\n","         [ 1.0204,  1.9767, -0.5619,  0.4166, -0.2817, -0.2651]],\n","\n","        [[ 1.2042,  1.3664,  0.7044,  0.8132,  0.2472, -0.6468],\n","         [ 0.6196,  0.7262, -0.7988, -0.1456, -1.8319, -1.1065]],\n","\n","        [[-1.1000,  0.3878, -0.2796, -1.1207,  1.8043,  0.1706],\n","         [ 0.6268, -0.6482,  1.5938,  0.7432, -0.7376, -1.3461]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Zmp1erKejHfB"},"source":["직접 구현한 코드를 보면 평균과 분산이 숫자 두개로 구성된 것을 알 수 있습니다. 이 두 경우 모두 구해진 평균과 분산에서 미니배치의 차원인 3이 사라진 것을 확인할 수 있습니다. 미니배치 내 샘플들끼리 평균과 분산을 구했기 때문입니다."]},{"cell_type":"markdown","metadata":{"id":"y0Bjbgh9IkDe"},"source":["만약 첫번째 예와 같은 상황에서 입력을 (3,4)로 했다면 평균과 분산을 구하는 방식이 조금 달라지게 됩니다.\n","\n","![picture](https://drive.google.com/uc?id=1hRLd1iV5wlLDF__VD4HtozaKnNgdgQYv)\n","\n","길이 6짜리 벡터를 더해서 평균벡터와 분산벡터를 구하는 상황입니다. 이런 식으로 동작하기 위해서 `(N,L)`에서 `L`을 `BatchNorm1d()`에 넘기면 됩니다. 아래 실험 코드가 있습니다. 이런 경우를 pytorch 문서에서는 'Temporal Batch Normalization'이라고 부릅니다. 미니배치에 있는 샘플들을 대상으로 `C`차원에 대해서 각각 구분해서 평균과 분산을 구해야 하는데 샘플에 `C`차원이 없어서 이렇게 이름 붙인것 같습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3ikbGuO_IcG","executionInfo":{"status":"ok","timestamp":1636599189782,"user_tz":-540,"elapsed":308,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"4bc10835-e95c-4aed-b4de-f7c44e64e9fb"},"source":["# 배치사이즈 3, 단어 한개로 구성된 문장, feature 4, 여기선 C가 없음\n","x = torch.randn(3, 4)\n","print('\\nINPUT', x.shape)\n","print(x)\n","\n","# 4차원 벡터를 6차원 벡터로 변환하는 완전연결 층\n","linear = nn.Linear(x.shape[-1], 6)\n","x = linear(x)\n","print('\\nACTIVATION', x.shape)\n","print(x)\n","\n","\n","# pytorch \n","bnorm = nn.BatchNorm1d(x.shape[1], eps=0., momentum=0.)\n","print('\\nPYTORCH BATCH NORM. 1D')\n","print(bnorm(x))\n","\n","# 직접 만들기\n","mean = x.mean(axis=0)\n","var = x.var(axis=0, unbiased=False)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nMY BATCH NORM.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT torch.Size([3, 4])\n","tensor([[ 1.8929,  3.1110, -0.4584, -0.3360],\n","        [-1.5700,  1.2315,  1.3946,  1.1711],\n","        [ 0.4335, -1.7343, -1.3360,  0.8871]])\n","\n","ACTIVATION torch.Size([3, 6])\n","tensor([[-0.8547,  0.8803, -0.9615,  0.1794, -0.1448, -1.3131],\n","        [-0.7770,  0.4903, -1.8076, -0.7847, -0.0231,  0.8162],\n","        [ 1.2591, -1.1274,  0.3239,  0.6613,  0.3677, -1.1282]],\n","       grad_fn=<AddmmBackward>)\n","\n","PYTORCH BATCH NORM. 1D\n","tensor([[-0.7464,  0.9195, -0.1671,  0.2673, -0.9670, -0.8009],\n","        [-0.6670,  0.4708, -1.1326, -1.3363, -0.4102,  1.4099],\n","        [ 1.4135, -1.3903,  1.2997,  1.0690,  1.3772, -0.6089]],\n","       grad_fn=<NativeBatchNormBackward>)\n","\n","MY BATCH NORM.\n","mean shape: torch.Size([6])\n","var shape: torch.Size([6])\n","tensor([[-0.7464,  0.9195, -0.1671,  0.2673, -0.9670, -0.8009],\n","        [-0.6670,  0.4708, -1.1326, -1.3363, -0.4102,  1.4099],\n","        [ 1.4135, -1.3903,  1.2997,  1.0690,  1.3772, -0.6089]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"TqfuardnJroG"},"source":["출력 샘플 하나가 길이 6짜리 벡터이므로 이런식으로 동작하는것이 좀 더 일반적인 경우라 할 수 있습니다. 버클리 대학교 인공지능 수업 [[cs182](https://cs182sp21.github.io/)]에서도 배치 정규화를 정확히 이렇게 설명하고 있습니다. 아래는 설명을 발췌한 슬라이드인데 수식을 보면 그냥 미니배치 안의 샘플들끼리 평균을 구하고 표준편차를 구하는 것을 확인할 수 있습니다.\n","\n","\n","\n","![picture](https://drive.google.com/uc?id=1YYnMN9hD6xJY5zNFvEG1nBslg4caMsVm)\n","\n","\n","이제 배치놈에 대해서 자세히 알아봤으니 레이어 정규화에 대해서 알아볼 차례입니다.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2UaGFngvorJh"},"source":["#### Layer Normalization\n","\n","레이어 정규화는 배치 정규화보다 개념이 간단합니다. 그냥 출력층 모양에 맞춰서 평균과 분산을 구하면 됩니다."]},{"cell_type":"markdown","metadata":{"id":"SBNh-Ryctc4N"},"source":["![picture](https://drive.google.com/uc?id=1jBGGDQPHCWppGLMuY0Nw0J48AYQ6SEHe)\n","\n","위 그림이라면 출력층이 숫자 여섯개인 벡터이므로 출력도 여섯개씩 묶어서 평균과 분산을 구하면 됩니다. 아래 코드에 실험결과가 있습니다.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PSYqF1MflWc6","executionInfo":{"status":"ok","timestamp":1636599192479,"user_tz":-540,"elapsed":280,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"989a66d8-56ea-4b06-a356-df41b44393c4"},"source":["torch.manual_seed(0)\n","\n","# 배치사이즈 3, 단어 한개로 구성된 문장, feature 4\n","x = torch.randn(3, 1, 4)\n","print('\\nINPUT', x.shape)\n","print(x)\n","\n","# 4차원 벡터를 6차원 벡터로 변환하는 완전연결 층\n","linear = nn.Linear(x.shape[-1], 6)\n","x = linear(x)\n","print('\\nACTIVATION', x.shape)\n","print(x)\n","\n","#===================\n","# layer norm.\n","# pytorch \n","# 정규화할 shape을 출력레이어 모양에 맞게 설정한다.\n","lnorm = nn.LayerNorm(x.shape[2], eps=0.)\n","print('\\nPYTORCH LAYER NORM.')\n","print(lnorm(x))\n","\n","# 직접 만들기\n","mean = x.mean(axis=-1).reshape(-1,1,1)\n","var = x.var(axis=-1, unbiased=False).reshape(-1,1,1)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nMY LAYER NORM.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)\n","#===================\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT torch.Size([3, 1, 4])\n","tensor([[[ 1.5410, -0.2934, -2.1788,  0.5684]],\n","\n","        [[-1.0845, -1.3986,  0.4033,  0.8380]],\n","\n","        [[-0.7193, -0.4033, -0.5966,  0.1820]]])\n","\n","ACTIVATION torch.Size([3, 1, 6])\n","tensor([[[-1.6115,  0.2043,  0.3828, -0.4272, -0.1355, -0.9343]],\n","\n","        [[-0.4144,  0.7838,  0.4598,  0.5056,  0.1713,  1.1928]],\n","\n","        [[-0.5397,  0.4543,  0.7689,  0.4446,  0.1475,  0.2965]]],\n","       grad_fn=<AddBackward0>)\n","\n","PYTORCH LAYER NORM.\n","tensor([[[-1.7441,  0.9143,  1.1757, -0.0102,  0.4169, -0.7525]],\n","\n","        [[-1.7336,  0.6699,  0.0201,  0.1118, -0.5586,  1.4903]],\n","\n","        [[-1.9794,  0.4748,  1.2514,  0.4509, -0.2829,  0.0851]]],\n","       grad_fn=<NativeLayerNormBackward>)\n","\n","MY LAYER NORM.\n","mean shape: torch.Size([3, 1, 1])\n","var shape: torch.Size([3, 1, 1])\n","tensor([[[-1.7441,  0.9143,  1.1757, -0.0102,  0.4169, -0.7525]],\n","\n","        [[-1.7336,  0.6699,  0.0201,  0.1118, -0.5586,  1.4903]],\n","\n","        [[-1.9794,  0.4748,  1.2514,  0.4509, -0.2829,  0.0851]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"RkBUeGbRpLCx"},"source":["그림처럼 출력을 층 모양에 맞게 묶어서 평균과 분산을 구하면 숫자가 세 개 구해지게 됩니다. 위 코드의 출력에서 마지막에 구한 `mean`, `var`의 `shape`을 확인해보면 숫자 세 개로 구성된 것을 알 수 있습니다. 적절한 자리에 빼고, 나누고 하기 위해 `reshape`을 적당히 해주면 pytorch 결과와 똑같은 결과를 만들 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"ElOAxxKZSgpm"},"source":["레이어 정규화를 두번째 예에 적용해보면 다음처럼 각 토큰별로 계산하게 됩니다."]},{"cell_type":"markdown","metadata":{"id":"Xl3ZJIt1tcxx"},"source":["![picture](https://drive.google.com/uc?id=1TXKgQMek9cq4a0-fS_krZ1U3lTIZO7mO)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tZgt1i4nBGF","executionInfo":{"status":"ok","timestamp":1636599195230,"user_tz":-540,"elapsed":320,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"49db0166-4b01-4dcf-aca1-32e0b73229c0"},"source":["# 배치사이즈 3, 단어 두 개로 구성된 문장, feature 4\n","x = torch.randn(3, 2, 4)\n","print('\\nINPUT', x.shape)\n","print(x)\n","\n","# 4차원 벡터를 6차원 벡터로 변환하는 완전연결 층\n","linear = nn.Linear(x.shape[-1], 6)\n","x = linear(x)\n","print('\\nACTIVATION', x.shape)\n","print(x)\n","\n","# pytorch \n","lnorm = nn.LayerNorm(x.shape[2], eps=0.)\n","print('\\npytorch layer norm.')\n","print(lnorm(x))\n","\n","# 직접 만들기\n","mean = x.mean(axis=-1).unsqueeze(-1)\n","var = x.var(axis=-1, unbiased=False).unsqueeze(-1)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nmy layer norm.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT torch.Size([3, 2, 4])\n","tensor([[[ 5.4329e-01, -3.9516e-01,  2.0553e-01, -4.5033e-01],\n","         [-5.7308e-01, -5.5536e-01,  5.9432e-01,  1.5419e+00]],\n","\n","        [[-1.0925e+00, -8.5194e-02, -9.3348e-02,  6.8705e-01],\n","         [-8.3832e-01,  8.9182e-04,  8.4189e-01, -4.0003e-01]],\n","\n","        [[ 6.2114e-01,  6.3818e-01, -2.4600e-01,  2.3025e+00],\n","         [-1.8817e+00, -4.9727e-02, -1.0450e+00, -9.5650e-01]]])\n","\n","ACTIVATION torch.Size([3, 2, 6])\n","tensor([[[-0.0636, -0.0346,  0.0337, -0.0617, -0.7393,  0.5536],\n","         [ 0.8464,  1.3011,  0.0941,  0.5593,  0.2273,  0.2352]],\n","\n","        [[ 0.6898,  0.7568,  0.4834,  0.5283,  0.2946, -0.0747],\n","         [ 0.6558,  0.7065, -0.0185,  0.2920, -0.5097, -0.1648]],\n","\n","        [[-0.2619,  0.3526,  0.0770, -0.2704,  0.9377,  0.2629],\n","         [ 0.6593,  0.0531,  1.1190,  0.7146,  0.0106, -0.2787]]],\n","       grad_fn=<AddBackward0>)\n","\n","pytorch layer norm.\n","tensor([[[-0.0308,  0.0462,  0.2279, -0.0258, -1.8293,  1.6118],\n","         [ 0.7188,  1.7990, -1.0687,  0.0366, -0.7522, -0.7334]],\n","\n","        [[ 0.8809,  1.1233,  0.1340,  0.2965, -0.5493, -1.8854],\n","         [ 1.1331,  1.2490, -0.4087,  0.3013, -1.5316, -0.7432]],\n","\n","        [[-1.0792,  0.4115, -0.2572, -1.1000,  1.8309,  0.1939],\n","         [ 0.5762, -0.6729,  1.5234,  0.6902, -0.7604, -1.3565]]],\n","       grad_fn=<NativeLayerNormBackward>)\n","\n","my layer norm.\n","mean shape: torch.Size([3, 2, 1])\n","var shape: torch.Size([3, 2, 1])\n","tensor([[[-0.0308,  0.0462,  0.2279, -0.0258, -1.8293,  1.6118],\n","         [ 0.7188,  1.7990, -1.0687,  0.0366, -0.7522, -0.7334]],\n","\n","        [[ 0.8809,  1.1233,  0.1340,  0.2965, -0.5493, -1.8854],\n","         [ 1.1331,  1.2490, -0.4087,  0.3013, -1.5316, -0.7432]],\n","\n","        [[-1.0792,  0.4115, -0.2572, -1.1000,  1.8309,  0.1939],\n","         [ 0.5762, -0.6729,  1.5234,  0.6902, -0.7604, -1.3565]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"m5L35Mg9r98c"},"source":["NLP에서는 시퀀스의 길이가 샘플마다 모두 달라서 패딩을 하게 되고 또 시퀀스 길이가 대체로 길어서 미니배치 사이즈를 크게 가져가지 못하기 때문에 배치 정규화를 사용하기 부적합하다고 판단하고 레이어 정규화를 사용했습니다."]},{"cell_type":"code","metadata":{"id":"f6IND4rKzp_O"},"source":["class LayerNorm(nn.Module):\n","    \"Construct a layernorm module (See citation for details).\"\n","    def __init__(self, features, eps=1e-6):\n","        super(LayerNorm, self).__init__()\n","        self.a_2 = nn.Parameter(torch.ones(features))\n","        self.b_2 = nn.Parameter(torch.zeros(features))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","\n","        # torch.nn.LayerNorm()과 맞추기 위해 unbiased=False로 수정\n","        std = x.std(-1, unbiased=False, keepdim=True)\n","        # std = x.std(-1, keepdim=True)\n","        \n","        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A4uqOeU7spJ8"},"source":["위에서 만든 레이어 정규화 층을 테스트 해봅시다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWZBASxl6VTt","executionInfo":{"status":"ok","timestamp":1636599198787,"user_tz":-540,"elapsed":12,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"7290bf98-5f0d-4188-9de7-d842809b6a10"},"source":["torch.manual_seed(0)\n","\n","# 배치사이즈 3, 단어 한개로 구성된 문장, feature 4\n","x = torch.randn(3, 1, 4)\n","print('\\nINPUT')\n","print(x)\n","\n","# 4차원 벡터를 6차원 벡터로 변환하는 완전연결 층\n","linear = nn.Linear(x.shape[-1], 6)\n","x = linear(x)\n","print('\\nACTIVATION')\n","print(x.shape)\n","\n","#===================\n","# layer norm.\n","# pytorch \n","lnorm2 = nn.LayerNorm(x.shape[-1], eps=0.)\n","print('\\nPYTORCH LAYER NORM.')\n","print(lnorm2(x))\n","\n","# 직접 만들기\n","mean = x.mean(axis=-1).reshape(-1,1,1)\n","var = x.var(axis=-1, unbiased=False).reshape(-1,1,1)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nMY LAYER NORM.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)\n","\n","# 레이어 층\n","lnorm = LayerNorm(x.shape[-1], eps=0.)\n","print('\\nclass LayerNorm')\n","print(lnorm(x))\n","\n","\n","#===================\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT\n","tensor([[[ 1.5410, -0.2934, -2.1788,  0.5684]],\n","\n","        [[-1.0845, -1.3986,  0.4033,  0.8380]],\n","\n","        [[-0.7193, -0.4033, -0.5966,  0.1820]]])\n","\n","ACTIVATION\n","torch.Size([3, 1, 6])\n","\n","PYTORCH LAYER NORM.\n","tensor([[[-1.7441,  0.9143,  1.1757, -0.0102,  0.4169, -0.7525]],\n","\n","        [[-1.7336,  0.6699,  0.0201,  0.1118, -0.5586,  1.4903]],\n","\n","        [[-1.9794,  0.4748,  1.2514,  0.4509, -0.2829,  0.0851]]],\n","       grad_fn=<NativeLayerNormBackward>)\n","\n","MY LAYER NORM.\n","mean shape: torch.Size([3, 1, 1])\n","var shape: torch.Size([3, 1, 1])\n","tensor([[[-1.7441,  0.9143,  1.1757, -0.0102,  0.4169, -0.7525]],\n","\n","        [[-1.7336,  0.6699,  0.0201,  0.1118, -0.5586,  1.4903]],\n","\n","        [[-1.9794,  0.4748,  1.2514,  0.4509, -0.2829,  0.0851]]],\n","       grad_fn=<AddBackward0>)\n","\n","class LayerNorm\n","tensor([[[-1.7441,  0.9143,  1.1757, -0.0102,  0.4169, -0.7525]],\n","\n","        [[-1.7336,  0.6699,  0.0201,  0.1118, -0.5586,  1.4903]],\n","\n","        [[-1.9794,  0.4748,  1.2514,  0.4509, -0.2829,  0.0851]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"-DfhA-Hatc6E"},"source":["pytorch의 `nn.LayerNorm()`과 앞서 직접 만들어본 레이어 정규화 결과와 클래스로 제공된 코드의 결과가 동일한 것을 알 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"bGrIJKhoVth5"},"source":["#### Instance Normalization\n","\n","참고 삼아 인스턴스 정규화에 대한 실험 코드도 아래 제시 했습니다. 인스턴스 정규화는 배치 차원과 채널 차원을 제외한 차원에 대해서 평균을 내는 방식입니다. 지금까지 사용한 예를 들어 알아보면 데이터가 (3,2,4)일 때 인스턴스 정규화를 적용하면 (3,2,$\\cdot$)차원에 대해서는 계산하지 않고 마지막 ($\\cdot$, $\\cdot$,4)차원인 네 개 숫자를 모두 더해서 4로 나눈 것이 평균이 됩니다. 그래서 평균과 분산은 (3,2,1)이 되고 이를 각 샘플과 채널에 대해서 정규화 하는 방식입니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNEkIwdtGddZ","executionInfo":{"status":"ok","timestamp":1636599201302,"user_tz":-540,"elapsed":295,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"a0413532-9c07-4f00-e7ab-8a53f90b0d43"},"source":["# 배치사이즈 3, 단어 두 개로 구성된 문장, feature 4\n","x = torch.randn(3, 2, 4)\n","print('\\nINPUT', x.shape)\n","print(x)\n","\n","# 4차원 벡터를 6차원 벡터로 변환하는 완전연결 층\n","linear = nn.Linear(x.shape[-1], 6)\n","x = linear(x)\n","print('\\nACTIVATION', x.shape)\n","print(x)\n","\n","#===================\n","# batch norm.\n","# pytorch \n","bnorm = nn.BatchNorm1d(x.shape[1], eps=0., momentum=0.)\n","print('\\nPYTORCH BATCH NORM. 1D')\n","print(bnorm(x))\n","# 직접 만들기\n","mean = x.mean(axis=(0,2)).reshape(-1,1)\n","var = x.var(axis=(0,2), unbiased=False).reshape(-1,1)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nMY BATCH NORM.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)\n","#===================\n","\n","#===================\n","# instance norm.\n","# pytorch \n","inorm = nn.InstanceNorm1d(x.shape[1], eps=0., momentum=0.)\n","print('\\nPYTORCH INSTANCE NORM. 1D')\n","print(inorm(x))\n","# 직접 만들기\n","mean = x.mean(axis=2).unsqueeze(2)#.reshape(-1,1)\n","var = x.var(axis=2, unbiased=False).unsqueeze(2)#.reshape(-1,1)\n","gamma = torch.ones(x.shape)\n","beta = torch.zeros(x.shape)\n","print('\\nMY INSTANCE NORM.')\n","print('mean shape:', mean.shape)\n","print('var shape:', var.shape)\n","print(((x - mean) / torch.sqrt(var))*gamma + beta)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT torch.Size([3, 2, 4])\n","tensor([[[ 5.4329e-01, -3.9516e-01,  2.0553e-01, -4.5033e-01],\n","         [-5.7308e-01, -5.5536e-01,  5.9432e-01,  1.5419e+00]],\n","\n","        [[-1.0925e+00, -8.5194e-02, -9.3348e-02,  6.8705e-01],\n","         [-8.3832e-01,  8.9182e-04,  8.4189e-01, -4.0003e-01]],\n","\n","        [[ 6.2114e-01,  6.3818e-01, -2.4600e-01,  2.3025e+00],\n","         [-1.8817e+00, -4.9727e-02, -1.0450e+00, -9.5650e-01]]])\n","\n","ACTIVATION torch.Size([3, 2, 6])\n","tensor([[[-0.0636, -0.0346,  0.0337, -0.0617, -0.7393,  0.5536],\n","         [ 0.8464,  1.3011,  0.0941,  0.5593,  0.2273,  0.2352]],\n","\n","        [[ 0.6898,  0.7568,  0.4834,  0.5283,  0.2946, -0.0747],\n","         [ 0.6558,  0.7065, -0.0185,  0.2920, -0.5097, -0.1648]],\n","\n","        [[-0.2619,  0.3526,  0.0770, -0.2704,  0.9377,  0.2629],\n","         [ 0.6593,  0.0531,  1.1190,  0.7146,  0.0106, -0.2787]]],\n","       grad_fn=<AddBackward0>)\n","\n","PYTORCH BATCH NORM. 1D\n","tensor([[[-0.6198, -0.5497, -0.3845, -0.6153, -2.2559,  0.8745],\n","         [ 1.0204,  1.9767, -0.5619,  0.4166, -0.2817, -0.2651]],\n","\n","        [[ 1.2042,  1.3664,  0.7044,  0.8132,  0.2472, -0.6468],\n","         [ 0.6196,  0.7262, -0.7988, -0.1456, -1.8319, -1.1065]],\n","\n","        [[-1.1000,  0.3878, -0.2796, -1.1207,  1.8043,  0.1706],\n","         [ 0.6268, -0.6482,  1.5938,  0.7432, -0.7376, -1.3461]]],\n","       grad_fn=<NativeBatchNormBackward>)\n","\n","MY BATCH NORM.\n","mean shape: torch.Size([2, 1])\n","var shape: torch.Size([2, 1])\n","tensor([[[-0.6198, -0.5497, -0.3845, -0.6153, -2.2559,  0.8745],\n","         [ 1.0204,  1.9767, -0.5619,  0.4166, -0.2817, -0.2651]],\n","\n","        [[ 1.2042,  1.3664,  0.7044,  0.8132,  0.2472, -0.6468],\n","         [ 0.6196,  0.7262, -0.7988, -0.1456, -1.8319, -1.1065]],\n","\n","        [[-1.1000,  0.3878, -0.2796, -1.1207,  1.8043,  0.1706],\n","         [ 0.6268, -0.6482,  1.5938,  0.7432, -0.7376, -1.3461]]],\n","       grad_fn=<AddBackward0>)\n","\n","PYTORCH INSTANCE NORM. 1D\n","tensor([[[-0.0308,  0.0462,  0.2279, -0.0258, -1.8293,  1.6118],\n","         [ 0.7188,  1.7990, -1.0687,  0.0366, -0.7522, -0.7334]],\n","\n","        [[ 0.8809,  1.1233,  0.1340,  0.2965, -0.5493, -1.8854],\n","         [ 1.1331,  1.2490, -0.4087,  0.3013, -1.5316, -0.7432]],\n","\n","        [[-1.0792,  0.4115, -0.2572, -1.1000,  1.8309,  0.1939],\n","         [ 0.5762, -0.6729,  1.5234,  0.6902, -0.7604, -1.3565]]],\n","       grad_fn=<ViewBackward>)\n","\n","MY INSTANCE NORM.\n","mean shape: torch.Size([3, 2, 1])\n","var shape: torch.Size([3, 2, 1])\n","tensor([[[-0.0308,  0.0462,  0.2279, -0.0258, -1.8293,  1.6118],\n","         [ 0.7188,  1.7990, -1.0687,  0.0366, -0.7522, -0.7334]],\n","\n","        [[ 0.8809,  1.1233,  0.1340,  0.2965, -0.5493, -1.8854],\n","         [ 1.1331,  1.2490, -0.4087,  0.3013, -1.5316, -0.7432]],\n","\n","        [[-1.0792,  0.4115, -0.2572, -1.1000,  1.8309,  0.1939],\n","         [ 0.5762, -0.6729,  1.5234,  0.6902, -0.7604, -1.3565]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"_YpOFnAEVsDz"},"source":["\n","이렇게 인코더를 구상하기 위한 기본 요소를 모두 알아봤습니다. 이제 이것들을 모아서 인코더를 만들어볼 차례입니다."]},{"cell_type":"markdown","metadata":{"id":"gs3nqJcxtkeN"},"source":["### EncoderLayer와 Encoder"]},{"cell_type":"markdown","metadata":{"id":"dgBBKFT1W3DC"},"source":["인코더는 다음 그림처럼 `SublayeConnection`, `EncoderLayer`, `Encoder`로 구성됩니다. 트랜스포머는 인코더와 디코더가 각각 N번 반복됩니다. 여기서 N번 반복되는 단위를 `EncoderLayer`로 구현하였고 이를 N번 복사하여 가지고 있는 클래스가 `Encoder`가 됩니다. `EncoderLayer`내부에는 `SublayerConnection`이 있게 됩니다. 각 클래스가 좀 복잡할 정도로 조각조각 나있다는 느낌이 드는데 전체적인 구조는 다음 그림과 같습니다.\n","\n","![picture](https://drive.google.com/uc?id=1a_MqSdbp9Ngjhkl6cNAUICb5tuDfBVjk)\n","\n","\n","그림은 보면 인코더는 `SublayerConnection`을 두 개, 디코더는 세 개 가지는 것을 알 수 있습니다.\n","\n"," 먼저 가장 기본 단위인 `SublayerConnection`부터 알아봅니다.\n"]},{"cell_type":"code","metadata":{"id":"wGmkKSRLzreJ"},"source":["class SublayerConnection(nn.Module):\n","    \"\"\"\n","    A residual connection followed by a layer norm.\n","    Note for code simplicity the norm is first as opposed to last.\n","    \"\"\"\n","    def __init__(self, size, dropout):\n","        super(SublayerConnection, self).__init__()\n","        self.norm = LayerNorm(size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, sublayer):\n","        \"Apply residual connection to any sublayer with the same size.\"\n","\n","        # (어텐션 or ff)-[드랍아웃]-Add and Norm으로 바꿨음\n","        # 드랍아웃은 논문에 sublayer에 썼다고 나와 있음\n","        # page 7        \n","        # We apply dropout [33] to the output of each sub-layer, \n","        # before it is added to the sub-layer input and normalized. \n","        # 층구성이 바뀌어서 아래쪽 hyperparam. warmup을 좀 키워야 됨\n","        # return x + self.dropout(sublayer(self.norm(x)))\n","        return self.norm(x + self.dropout(sublayer(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXnnsxlauzzB"},"source":["`SublayerConnection`은 내부적으로 `LayerNorm`과 `Dropout`만 가지고 있습니다. 포워들 할 때 외부에서 `sublayer`를 넘겨받아 이 `sublayer`를 포워드 시키고 내부에 있는 드롭아웃과 정규화를 적용하는 식으로 동작합니다. \n","\n","그래서 `sublayer`가 어텐션 레이어이면 위 그림 아래쪽 회식 박스에 해당하고 피드 포워드 레이어이면 윗쪽 회색 박스에 해당하게 되겠습니다."]},{"cell_type":"markdown","metadata":{"id":"9LQf0QJhXMV0"},"source":["`EncoderLayer`는 `SublayerConnection`을 두 개 가지고 있습니다. 그리고 이 위 그림에서 확인할 수 있듯이 `SublayerConnection` 두 개는 각각 (어텐션 레이어, Add & Norm)과 (피드포워드 레이어, Add & Norm)으로 구성됩니다."]},{"cell_type":"code","metadata":{"id":"a3l2Ya1Bzs7U"},"source":["class EncoderLayer(nn.Module):\n","    \"Encoder is made up of self-attn and feed forward (defined below)\"\n","    def __init__(self, size, self_attn, feed_forward, dropout):\n","        super(EncoderLayer, self).__init__()\n","        \n","        # self_attn: MultiHeadedAttention\n","        self.self_attn = self_attn\n","\n","        # feed_forward: PositionwiseFeedForward\n","        self.feed_forward = feed_forward \n","        \n","        # SublayerConnection이 2개\n","        self.sublayer = clones(SublayerConnection(size, dropout), 2) \n","        self.size = size # d_model\n","\n","    def forward(self, x, mask):\n","        \"Follow Figure 1 (left) for connections.\"\n","        # 1. 어텐션으로 람다 함수를 만들어서 sublayer[0]에 x와 함께 전달\n","        #    이때 어텐션 \n","        # 2. sublayer[0]가 포워드 되면서\n","        # 3. 레이어노멀 하고\n","        # 4. 인자로 넘긴 람다 함수가 sublayer로 돌면서 어텐션하고\n","        # 5. 드랍아웃하고 \n","        # 6. x와 더해져서 리턴 \n","        # 그냥 self_atten을 바로 넘기지 않는 이유는 self_attn에 x, mask를 같이 받기 때문에\n","        # x만 인자로 만들려고\n","        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n","        # 원래 코드는 이 시점에서 \n","        # x는 레이어놈-어텐션-드랍아웃-스킵커넥션 까지 됨\n","        # 하지만 위 SublayerConnection.forward에서 순서를 원래 논문 순서로 맞춰서\n","        # 어테션-드랍아웃-스킵커넥션-레이어놈 이 되었음\n","        \n","        # 7. 위와 마찬가지로 \n","        # 원 코드 순서는 레이어놈-ff-드랍아웃-스킵커넥션\n","        # 코드를 고쳐서 여기서도 \n","        # ff-드랍아웃-스킵커넥션-레이어놈\n","        return self.sublayer[1](x, self.feed_forward)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N5bU41I3XYAZ"},"source":["`EncoderLayer`는 내부적으로 `MultiHeadedAttention`과 `PositionwiseFeedForward`을 가지고 있습니다. 그리고 `SublayerConnection`을 두개 가지고 이 `SublayerConnection` 포워드 시킬 때 `layer`인자로 `MultiHeadedAttention`과 `PositionwiseFeedForward`을 각각 전달하게 됩니다. 그림을 보면 그림과 동일하게 구현되어 있음을 알 수 있습니다.\n","\n","이제 마지막으로 `Encoder`입니다. `Encoder`는 생성자로 넘어오는 `EncoderLayer`를 N개 복사하고 포워드시 각각을 포워드 시키는 간단한 구조로 작성되었습니다."]},{"cell_type":"code","metadata":{"id":"xZR1YxShzoJc"},"source":["class Encoder(nn.Module):\n","    \"Core encoder is a stack of N layers\"\n","    def __init__(self, layer, N):\n","        super(Encoder, self).__init__()\n","        \n","        # make_model()함수에서 아래처럼 생성될 예정\n","        # Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N)\n","        # 여기 layer는 EncoderLayer\n","        self.layers = clones(layer, N) \n","        self.norm = LayerNorm(layer.size)\n","        \n","    def forward(self, x, mask):\n","        \"Pass the input (and mask) through each layer in turn.\"\n","        # self.layers에는 EncoderLayer 여섯 개가 순차적으로 있음\n","        # 이 함수는 다음처럼 호출됨\n","        # EncoderDecoder.encode(\n","        #     self.encoder(self.src_embed(src), src_mask)\n","        # )\n","        # src_mask: (nbatches, 1, n_seq_src)\n","        \n","        for layer in self.layers: \n","            # 여기 layer는 EncoderLayer고 EncoderLayer를 포워드 시킨다.\n","            # EncoderLayer포워드는 위 EncoderLayer 주석참고\n","            x = layer(x, mask) \n","        \n","        # 논문 그림 구조와 맞추기 위해 SublayerConnection에서 norm하고\n","        # 여기선 안하는 것으로 바꿈\n","        # return self.norm(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QNN5Hxlotn0Y"},"source":["### Positionwise Feed Forward"]},{"cell_type":"code","metadata":{"id":"Wg2ZuCqpz-bD"},"source":["class PositionwiseFeedForward(nn.Module):\n","    \"Implements FFN equation.\"\n","    def __init__(self, d_model, d_ff, dropout=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.w_1 = nn.Linear(d_model, d_ff)\n","        self.w_2 = nn.Linear(d_ff, d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        return self.w_2(self.dropout(F.relu(self.w_1(x))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hwaq4h6cj7S7"},"source":["인코더에서 $(n_{\\text{seq}}, d_{\\text{model}})$ 크기를 가지는 텐서를 두번 Linear 층에 통과 시키게 되는데 이를 positionwise feed forward라고 이야기했습니다. 위 구조 그림에서 하늘색으로 표시된 부분입니다. 코드를 보면 가중치 행렬을 두번 곱하게 되는데 각 곱에 대해서 크기는 다음처럼 변하게 됩니다.\n","\n","$(n_{\\text{seq}}, d_{\\text{model}}) \\to (n_{\\text{seq}}, d_{\\text{ff}}) \\to (n_{\\text{seq}}, d_{\\text{model}})$\n","\n","이 변환은 $n_{\\text{seq}}$의 각 자리에 해당하는 토큰 표현 벡터를 $d_{\\text{model}}$에서 $d_{\\text{ff}}$로 변환했다 다시 $d_{\\text{model}}$차원으로 되돌리는 것입니다. positionwise라고 이름지은 이유는 각 토큰 표현에 해당하는 n_seq개 벡터가 각각 $d_{\\text{ff}}$로 변환되었다 다시 $d_{\\text{model}}$ 크기로 돌아오기 때문입니다."]},{"cell_type":"markdown","metadata":{"id":"vkzmc8hxYvNQ"},"source":["이렇게 인코더에 대해서 모두 알아봤습니다. 인코더를 잘 이해하면 디코더를 80% 이상 이해한것입니다. 디코더에서는 추가로 고려해야할 사항을 중심으로 이야기 하도록 하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"H9pXBAPMzzfB"},"source":["## Decoder"]},{"cell_type":"markdown","metadata":{"id":"YH77gBTLqj_N"},"source":["### 디코더에 적용되는 마스크\n","\n","디코더에도 셀프 어텐션이 적용되는데 이 때는 이미 생성된 토큰 끼리만 어텐션 해야 합니다. 아직 생기지도 않은<sup>&#8224;</sup> 토큰과 어텐션할 수 없기 때문입니다.  seq2seq 모델처럼 시간순으로 타겟 토큰을 입력한다면 이는 자연스럽게 해결되지만 트랜스포머는 학습시 디코더에 모든 정답 토큰이 입력되므로 아직 어텐션 하지 않아아 될 부분을 지워내야 합니다. 그렇게 하기 위해 디코더에 입력되는 정답 시퀀스 길이를 행과 열로 가지는 마스크 행렬을 만드는데 이 행렬은 하삼각 요소와 주대각선만 1이고 상삼각행렬은 0을 가지게 됩니다. \n","\n","\n","---\n","<sup>&#8224;</sup> \"아직 생기지도 않은\" 이란 표현에서 뭔가 혼란스러움을 느꼈다면 충분히 그럴 수 있습니다. 트랜스포머에는 모든 정답 토큰이 디코더로 한꺼번에 입력된다고 했는데 마치 시간 순으로 토큰이 디코딩 되는 듯한 \"아직 생기지도 않은\"이란 표현은 뭔가 어색하기 짝이 없습니다. 이런 이유 때문에 디코더쪽 마스킹을 이해하기 힘들어지는데 어떻게 표현하면 더 자연스러울지 잘 떠오르지 않아서 계속 고민중에 있습니다."]},{"cell_type":"code","metadata":{"id":"tegWgGgDz3EU"},"source":["def subsequent_mask(size):\n","    \"Mask out subsequent positions.\"\n","    attn_shape = (1, size, size)\n","    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n","    return torch.from_numpy(subsequent_mask) == 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BRy3OXfI0Gzo"},"source":["위 코드는 행과 열 수가 입력 토큰 수이고 상삼각 행렬이 모두 0인 행렬을 만드는 코드입니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"FwfScgrCz4dP","executionInfo":{"status":"ok","timestamp":1636599216773,"user_tz":-540,"elapsed":409,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"212f4706-b7f4-472f-c66b-87037c74320b"},"source":["plt.figure(figsize=(5,5))\n","\n","sub_mask = subsequent_mask(20)\n","print(sub_mask.shape)\n","plt.imshow(sub_mask[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 20, 20])\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7efe9d759f50>"]},"metadata":{},"execution_count":25},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAToAAAEuCAYAAAAeBd7RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ80lEQVR4nO3dXaxdZZ3H8e9/zvASxQta6yTDiNxgjDIwCScSuMA0YoQJsYxM8MIYuZADoxJBLkQzEkIZTFAmxAuREt+CDQmG2IIYEYTAhNECCYwGJSMkGnUiU9sQ04JMW35zcXbr7u4+Ze+19jk9ffx+EsJZz/Osvf5nnb1/rJe9HioJktSyvzrSBUjScjPoJDXPoJPUPINOUvMMOknNM+gkNe+vj3QBo968Zi6nvPWYqdf775++YRmqkXS0+BO7+b+8WuP6Vl3QnfLWY3jigbdOvd77//YflqEaSUeLbfnRkn2eukpqnkEnqXm9Tl2r6sPAh4B9wI+T3DxNvySthM5HdFX1JuAjwIYk/wT8fVWdOmm/JK2UPqeu5wAP5s+zAmwF1k/RL0krok/QrQV2Di3vHLRN2n9AVS1U1VNV9dT2Hft6lCRJh+oTdDuAE4eW1wzaJu0/IMmmJPNJ5tetnetRkiQdqk/QbQPOq6r9X9D7APDYFP2StCI633VN8lJV3QncVVV7gWeSPDdpvyStlF5fL0lyF3DXcFtV3QNckmTfuH5JWmkzfwQsycWzfk1J6sMnIyQ1b9U91N/VA//zzNTrOBGA9JfBIzpJzTPoJDXPoJPUPINOUvMMOknNM+gkNc+gk9Q8g05S8ww6Sc0z6CQ1z6CT1DyDTlLzmnmov4suEwGAkwFIRxuP6CQ1z6CT1DyDTlLzDDpJzTPoJDXPoJPUPINOUvMMOknNM+gkNc+gk9S8Xo+AVdVtwGvAGuD+JN8e6X8IeH6o6dokL/XZpiRNq1fQJfkXgKoq4DHg22PGXNFnG5LU16we6j8O2DmmfVdVbQROAR5LcseMtidJE5tV0N0I3DzamOQiOHDEd1tVvZDk4dFxVbUALACcfNLqn1Cly6wnzngiHTm9b0ZU1dXA00keX2pMkgD3Aacv0b8pyXyS+XVr5/qWJEkH6RV0VfVxYHeSzRMMPxd4ss/2JKmLzueJVXUOcC3w/ar66qD580m2D425BTgBOB7YdrijPklaLp2DLsl/AiePtlfV7cB1SV5Mck2f4iRpFmZ+5T/J5bN+TUnqwycjJDXPoJPUPINOUvMMOknNM+gkNc+gk9Q8g05S81b/E/SN6DIRADgZgDQLHtFJap5BJ6l5Bp2k5hl0kppn0ElqnkEnqXkGnaTmGXSSmmfQSWqeQSepeQadpOYZdJKaZ9BJap6zl6xyznoi9ecRnaTmGXSSmmfQSWpe52t0VfU0sG2wuBe4MklGxpwHXA3sBn6b5NNdtydJXfW5GbEjyRVLdVZVAZ8F/jHJq1V1Y1W9L8mDPbYpSVPrc+o6V1VfqKrNVXXRmP63Az9P8upgeQuwvsf2JKmTzkd0SdYDVNUxwHeq6tkkvxwashbYObS8c9B2iKpaABYATj7Jb7xImq3eNyOS7AEeBN410rUDOHFoec2gbdxrbEoyn2R+3dq5viVJ0kFmddf1bGD0m63PA6dV1XGD5Q3AozPaniRNrM9d128BrwAnAFuS/Gq4P8m+qtoIbK6qXcB24Ic9apWkTvpco/vouPaquh24LsmLSR4BHum6DUmahZlf+U9y+axfU5L68MkISc3zuxyN6jLriTOeqFUe0UlqnkEnqXkGnaTmGXSSmmfQSWqeQSepeQadpOYZdJKaZ9BJap5BJ6l5Bp2k5hl0kprnQ/06oMtEAOBkAFr9PKKT1DyDTlLzDDpJzTPoJDXPoJPUPINOUvMMOknNM+gkNc+gk9Q8g05S8zo/AlZV7wCuGmo6G7gsyRNDY54Gtg0W9wJXJknXbUpSF52DLslzwBUAVTUHbAWeHBm2I8kV3cuTpP5mdep6MbB1zNHaXFV9oao2V9VFM9qWJE1lVrOXXAp8cLQxyXqAqjoG+E5VPZvkl6PjqmoBWAA4+SQnVDnadJn1xBlPtJJ6H9FV1XuBnyT501JjkuwBHgTetUT/piTzSebXrZ3rW5IkHWQWp66fBL4ywbizgW4TnklSD73OE6vqDOB3Sf6wRP+3gFeAE4AtSX7VZ3uS1EWvoEvyXywe0R1QVfcAlyTZl+SjfV5fkmZh5lf+k1w869eUpD58MkJS8ww6Sc0z6CQ1z6CT1DyDTlLzDDpJzTPoJDXPJ+h1RHSZCACcDEDdeEQnqXkGnaTmGXSSmmfQSWqeQSepeQadpOYZdJKaZ9BJap5BJ6l5Bp2k5hl0kppn0ElqnkEnqXnOXqKjirOeqAuP6CQ1z6CT1DyDTlLzJgq6qpqrqn+rqh8MtZ1XVfdX1d1V9e9LrPe6YyRpuU16RHchcC+DmxdVVcBngQ8muQR4uareN7zCJGMkaSVMFHRJtibZNtT0duDnSV4dLG8B1o+sNskYSVp2Xa/RrQV2Di3vHLRNOwaAqlqoqqeq6qntO/Z1LEmSxusadDuAE4eW1wzaph0DQJJNSeaTzK9bO9exJEkar2vQPQ+cVlXHDZY3AI92GCNJy27aJyP2ACTZV1Ubgc1VtQvYDvxweOAkYyRpJUwVdEkuGPr5EeCR0TFVdTtwXZIXlxojSStp5s+6Jrl81q8pSX34ZISk5jl7if4idJn1xBlP2uERnaTmGXSSmmfQSWqeQSepeQadpOYZdJKaZ9BJap5BJ6l5Bp2k5hl0kppn0ElqnkEnqXk+1C8toctEAOBkAKuRR3SSmmfQSWqeQSepeQadpOYZdJKaZ9BJap5BJ6l5Bp2k5hl0kppn0Elq3kSPgFXVHHADcGaS8wdtNwJrgDcCP0vypTHrfQ04Ftg9aPpikhdmUbgkTWrSZ10vBO4FztrfkORf9/9cVQ9U1W1Jdo+sNwd8Nslve1cqSR1NFHRJtgJU1SF9tdj4GvDKmFV3A1dV1ZuB54Cbk7zWuVpJ6mAWs5d8CvjGuABL8on9P1fV54BLga+PjquqBWAB4OSTnFBFR7cus54448ny6nUzoqouAY5NcvcEw7cCp4/rSLIpyXyS+XVr5/qUJEmH6Bx0VbUBeGeSmydc5T3AE123J0ldTXueuAegqt4GbAK+W1VfHfTdmuS54cGD09VTWLwp8ZskX+lXriRNb6qgS3LB4N+/Bv5m3Jiquh7YkuSZJDf1rlCSepr5lf8k18/6NSWpD5+MkNQ8g05S8ww6Sc0z6CQ1z6CT1DyDTlLzDDpJzfMJemkV6DIRADgZwKQ8opPUPINOUvMMOknNM+gkNc+gk9Q8g05S8ww6Sc0z6CQ1z6CT1DyDTlLzDDpJzTPoJDXPoJPUPGcvkY5iznoyGY/oJDXPoJPUPINOUvMmukZXVXPADcCZSc4ftD0EPD807NokL42sdwZwE7ALeBlYSLJnFoVL0qQmvRlxIXAvcNZwY5IrXme9m4CPJNlZVR8DLgXumLZISepjolPXJFuTbBtp3lVVG6vqzqq6bHSdqjoe2Jtk56BpC7C+X7mSNL3OXy9JchFAVRVwW1W9kOThoSFrgOFT2Z2DtkNU1QKwAHDySX7jRdJs9b4ZkSTAfcDpI107gBOHltewGHbjXmNTkvkk8+vWzvUtSZIOMqu7rucCTw43JHkVOKaq9ofdBuDRGW1PkiY27XnigTumVXULcAJwPLAtyeNjxn8GuKOq/gjsBa7sWqgkdTVV0CW5YOjna8aNqarrgS1JnknyU+Cfe1UoST3N/Mp/kutn/ZqS1IdPRkhqnt/lkP4CdZn15Gie8cQjOknNM+gkNc+gk9Q8g05S8ww6Sc0z6CQ1z6CT1DyDTlLzDDpJzTPoJDXPoJPUPINOUvN8qF/SRLpMBACrYzIAj+gkNc+gk9Q8g05S8ww6Sc0z6CQ1z6CT1DyDTlLzDDpJzTPoJDXPoJPUvIkeAauqOeAG4Mwk51fVOmDj0JDTgC8nuXtkvYeA54eark3yUs+aJWkqkz7reiFwL3AWQJLtwBX7O6vqHuB741ZMcsW4dklaKRMFXZKtAFV1SF9VvRv4RZKXx6y6q6o2AqcAjyW5o3upktTNLGYvuQr49LiOJBcB1GJC3lZVLyR5eHRcVS0ACwAnn+SEKlJLusx6MusZT3rdjKiqU4HdSX5/uHFJAtwHnL5E/6Yk80nm162d61OSJB2i713Xa4BbJxx7LvBkz+1J0tSmPU/cs/+HqnoLsC7Js0sNrqpbgBOA44FtSR7vVKUk9TBV0CW5YOjn/wUuHh1TVbcD1yV5Mck1/UuUpH5mfuU/yeWzfk1J6sMnIyQ1z6CT1DyDTlLzDDpJzTPoJDXPoJPUPINOUvN8gl7SqtNlIoB3v3/cBEqLPKKT1DyDTlLzDDpJzTPoJDXPoJPUPINOUvMMOknNM+gkNc+gk9Q8g05S8ww6Sc0z6CQ1z6CT1LxKcqRrOEhVbQd+PabrzcAfVriccazjYNZxMOs42ErW8bYk68Z1rLqgW0pVPZVk3jqswzqsY1qeukpqnkEnqXlHU9BtOtIFDFjHwazjYNZxsFVRx1FzjU6SujqajugkqRODTlLzVt3/BayqPgx8CNgH/DjJzdP0z7CO24DXgDXA/Um+PdL/EPD8UNO1SV5ahjqeBrYNFvcCV2bkekNVnQdcDewGfpvk0zOu4R3AVUNNZwOXJXlimjp7bH8OuAE4M8n5g7bX/Z1nvV+WqONGFt8jbwR+luRLY9b7GnDsoA6ALyZ5YcZ1vO77sarOAG4CdgEvAwtJ9syqjqpaB2wcGnIa8OUkd4+styKfnYMkWTX/AG8CfsCfrx3eCZw6af8y1VTAf4xpf2iF9slhtzOo70fAcYPlG4H3LWM9c8D39v8NVmJ/ABuAs/ZvY5LfeTn2y2gdY/ofAN44pv2bwN8t1/6YdP8D9wNrBj9/jMX/WC3n/rgHeMOY9hX57Az/s9pOXc8BHsxgbwBbgfVT9C+H44CdY9p3VdXGqrqzqi5bxu3PVdUXqmpzVV00pv/twM+TvDpY3sLy7pOLga1Df4NJ6+wsydYk24aaJvmdZ75fxtRxQFUVi2cAr4zp3g1cVVXfrKprq6rX526JOg77fqyq44G9Sfa/l5d7f7wb+EWScf+z1ZX67Byw2k5d13JwqOwETp2ifzncCBxyepzkIjjwBr+tql5I8vCsN55k/WA7xwDfqapnk/xyaMi4fbJ21nUMuRT4YIc6Z2mS33ml98ungG8keW20I8kn9v9cVZ9jcR9+fZYbn+D9uAYYPj3cOWhbLlcBYy8VrNRnZ9hqO6LbAZw4tLxm0DZp/0xV1dXA00keX2rM4MjmPuD05apjsJ09wIPAu0a6VmyfVNV7gZ8k+dNSYw5T5yxN8juv5H65BDg2I9eilrCVZXyvHOb9OG5/jDtT6a2qTgV2J/n94cat1GcHVl/QbQPOGyQ9wAeAx6bon5mq+jiLf6zNEww/F3hyOeoYcTbwzEjb88BpVXXcYHkD8Ogybf+TwFcmGDeuzlma5Hdekf1SVRuAd2bym2LvAZ543VH9HPJ+HJzCH1NV+8NuOd8n1wC3Tjh2RT47q+rUNclLVXUncFdV7QWeSfLcpP2zUlXnANcC36+qrw6aP59k+9CYW4ATgOOBbYc76utZy7dYvO5zArAlya+G+5Psq6qNwOaq2gVsB364DHWcAfwuydiZKF6vzhnZA5P9zsu8X/YAVNXbWPzm/3eH3ie3jr4nB6erp7B4I+c3SSb5j8XEdQy2Mcn78TPAHVX1RwZ3xpehjrcA65I8u9TglfrsHLTNQ68prz5VdQ9wSZJ9R7iO24Hrkrx4JOtYLbWslr/LsNWwXwZ1XM9i4C/nke3RVMcR/bscFUEnSX2stmt0kjRzBp2k5hl0kppn0ElqnkEnqXkGnaTm/T+Y5LOR9eyGIAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 360x360 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ut7ZGkxI0ilu"},"source":["이 마스크가 어떻게 적용되는지는 뒤에 상세히 예를 들어 설명하도록 하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"loOPaKHueQsH"},"source":["### DecoderLayer와 Decoder\n","\n","`DecoderLayer`와 `Decoder`의 구성은 인코더와 동일합니다. 한가지 다른 점은 `DecoderLayer`에는 어텐션이 두 개 있다는 점입니다. `forward()`함수를 보면 알 수 있듯이 셀프 어텐션과 인코더, 디코더 간의 크로스 어텐션입니다. \n"]},{"cell_type":"code","metadata":{"id":"XqWPxChez1h2"},"source":["class DecoderLayer(nn.Module):\n","    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n","    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n","        # self_attn: MultiHeadedAttention\n","        # src_attn: MultiHeadedAttention\n","\n","        super(DecoderLayer, self).__init__()\n","        self.size = size\n","        self.self_attn = self_attn\n","        self.src_attn = src_attn # cross attention\n","        self.feed_forward = feed_forward # positional ff\n","        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n"," \n","    def forward(self, x, memory, src_mask, tgt_mask):\n","        \"Follow Figure 1 (right) for connections.\"\n","        # 여기서 momory는 인코더로 부터 넘어온 인코딩 (nbatche, n_seq, d_model)\n","        m = memory\n","        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n","        \n","        # 크로스 어텐션 할 때 마스크는 src_mask(key_pad_mask)를 전달함!\n","        # 이렇게 하면 입력에 존재하는 패딩 토큰이 쿼리로써 인코딩되어 온 것을 \n","        # key 패딩으로 마스킹 할 수 있게 된다.\n","        # (인코더 출력이 이제는 key로 작용하기 때문에!!!)\n","        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n","        \n","        return self.sublayer[2](x, self.feed_forward)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SsqlIIgdg27H"},"source":["크로스 어텐션를 실행하는 코드를 보면 \n","\n","```python\n","# x: 디코더에서 만든 (n_seq, d_mode) 텐서 (여기서 n_seq는 디코더로 입력되는 시퀀스의 길이)\n","# m: 인코더에서 전달받은 (n_seq, d_model) 텐서 (여기서 n_seq는 인코더로 입력된 시퀀스의 길이)\n","x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n","```\n","\n","셀프 어텐션과 차이는 쿼리로 디코더의 입력이 인코딩된 것을 넘기고 키와 벨류는 인코더에서 입력받는 인코딩 정보를 넘긴다는 것입니다. 이렇게 해야 크로스 어텐션이 계산되겠죠. 또 마스크는 `src_mask`를 넘기고 있는 것을 확인할 수 있습니다. 이에 대한 자세한 설명은 아래 [실험용 데이터와 보조 코드 준비](#cell-id)절에서 모두 설명하도록 하겠습니다.\n","\n","아래는 `Decoder` 코드이고 특별히 언급할 점은 없습니다."]},{"cell_type":"code","metadata":{"id":"EutLhZ9Ezu08"},"source":["class Decoder(nn.Module):\n","    \"Generic N layer decoder with masking.\"\n","    def __init__(self, layer, N):\n","        # layer: DecoderLayer\n","\n","        super(Decoder, self).__init__()\n","        self.layers = clones(layer, N)\n","        self.norm = LayerNorm(layer.size)\n","        \n","    def forward(self, x, memory, src_mask, tgt_mask):\n","        for layer in self.layers:\n","            x = layer(x, memory, src_mask, tgt_mask)\n","        \n","        # Encoder와 마찬가지로 norm 안함\n","        # return self.norm(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_fkVa3LgqArF"},"source":["### 디코더 끝에 붙는 마지막 Linear 레이어\n","\n","디코더의 출력을 받아서 최종적으로 $(n_{\\text{seq}}, d_{\\text{model}})$을 $(n_{\\text{seq}}, \\text{vocab})$로 변환하는 피드 포워드 레이어를 추가합니다."]},{"cell_type":"code","metadata":{"id":"4UeVvfIOzkoF"},"source":["class Generator(nn.Module):\n","    \"Define standard linear + softmax generation step.\"\n","    def __init__(self, d_model, vocab):\n","        super(Generator, self).__init__()\n","        self.proj = nn.Linear(d_model, vocab)\n","\n","    def forward(self, x):\n","        return F.log_softmax(self.proj(x), dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9k4OcZItp8aa"},"source":["\n","\n","## Transformer"]},{"cell_type":"markdown","metadata":{"id":"4IH3c-I1h9Ry"},"source":["이상에서 만든 부품들로 트랜스포머를 조립합니다. `Encoder`, `Decoder`를 받아서 전체 모델을 생성하는 `EncoderDecoder` 클래스를 정의하고 이것을 객체로 생성하는 `make_model()` 함수를 정의합니다.\n","\n","아래 그림은 `make_model()` 함수가 조립하는 전체 구조를 주석과 함께 나타낸 것입니다.\n","\n","![picture](https://drive.google.com/uc?id=1aQKj79KnivzAaQ2pVz6103kQ1hf4klBQ)\n"]},{"cell_type":"code","metadata":{"id":"N26U07Vmze0L"},"source":["class EncoderDecoder(nn.Module):\n","    \"\"\"\n","    A standard Encoder-Decoder architecture. Base for this and many \n","    other models.\n","    \"\"\"\n","    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n","        super(EncoderDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_embed = src_embed # 인코더의 임베딩-위치인코딩\n","        self.tgt_embed = tgt_embed # 디코더의 임베딩-위치인코딩\n","        self.generator = generator\n","\n","    # 이 함수가 모델이 포워드 되는 엔트리 포인트!!!    \n","    def forward(self, src, tgt, src_mask, tgt_mask):\n","        \"Take in and process masked src and target sequences.\"\n","        return self.decode(\n","            self.encode(src, src_mask), src_mask,\n","            tgt, tgt_mask\n","        )\n","    \n","    def encode(self, src, src_mask):\n","        return self.encoder(self.src_embed(src), src_mask)\n","    \n","    def decode(self, memory, src_mask, tgt, tgt_mask):\n","        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XrFUFtJ82r89"},"source":["마지막으로 `Encoder`와 `Decoder`를 한번 더 감싸서 `EncoderDecoder` 클래스를 만듭니다. 이 클래스의 `forward`함수가 모델을 포워드시키는 엔트리 포인트가 됩니다."]},{"cell_type":"code","metadata":{"id":"lKThOQWr0DGO"},"source":["def make_model(src_vocab, tgt_vocab, N=6, \n","               d_model=512, d_ff=2048, h=8, dropout=0.1):\n","    \"\"\"\n","        Helper: Construct a model from hyperparameters.\n","        src_vocab: 입력을 임베딩할 때 사용하는 단어장 사이즈\n","        tgt_vocab: 출력을 위한 출력쪽 단어장 사이즈\n","        d_mode: 트랜스포머 인코더 디코더에서 사용되는 벡터의 크기\n","        d_ff: feed foward층이 출력하는 벡터의 크기\n","    \"\"\"\n","    c = copy.deepcopy\n","    attn = MultiHeadedAttention(h, d_model)\n","    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n","    position = PositionalEncoding(d_model, dropout)\n","    model = EncoderDecoder(\n","        # 인코더를 만들기 위해 어텐선 레이어 하나와 피드포워드 레이어 하나가 필요합니다.\n","        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n","        \n","        # 디코더를 만들기 위해 어텐션 레이어 두개와 피드포워드 레이어 하나가 필요합니다.\n","        # 두 어텐션 레이어 중 하나는 셀프 어텐션을 담당하고 하나는 크로스 어텐션을 담당합니다.\n","        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n","                             c(ff), dropout), N),\n","\n","        # 인코더와 디코더 쪽 임베딩으로 직접 만든 토큰 임베딩과\n","        # 포지션 인코딩을 순차적으로 수행하는 nn.Sequential                   \n","        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n","        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n","\n","        Generator(d_model, tgt_vocab))\n","    \n","    # This was important from their code. \n","    # Initialize parameters with Glorot / fan_avg.\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            # nn.init.xavier_uniform(p)\n","            nn.init.xavier_uniform_(p)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W_htqhWmeyKG"},"source":["마지막으로 트랜스포머를 조립하는 `make_model` 함수입니다. 지금까지 내용을 충분히 이해했다면 여기서 모델을 만드는 코드가 한눈에 들어올 것입니다.\n","\n","\n","이상없이 모델이 만들어지는지 테스트 합니다."]},{"cell_type":"code","metadata":{"id":"Aa2is5Bd0FGO"},"source":["tmp_model = make_model(10, 10, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WFTdWsxYDoZU"},"source":["<a name=\"cell-id\"></a>\n","## 실험용 데이터와 보조 코드 준비"]},{"cell_type":"markdown","metadata":{"id":"J_2JoQDfe4O1"},"source":["이렇게 모델에 대한 코딩을 모두 마쳤고 이제 간단한 실험을 위한 코드를 알아보도록 하겠습니다. 먼저 `Batch`클래스입니다."]},{"cell_type":"code","metadata":{"id":"sUD6rROm0Hf2"},"source":["class Batch:\n","    \"Object for holding a batch of data with mask during training.\"\n","    def __init__(self, src, trg=None, pad=0):\n","        # src: (nbatches, n_seq_src)\n","        self.src = src\n","        self.src_mask = (src != pad).unsqueeze(-2) # (nbatches, 1, n_seq_src)\n","        if trg is not None:\n","            self.trg = trg[:, :-1]\n","            self.trg_y = trg[:, 1:]\n","            self.trg_mask = self.make_std_mask(self.trg, pad) # (nbatches, n_seq_trg, n_seq_trg)\n","            self.ntokens = (self.trg_y != pad).data.sum() # 패딩 토큰이 아닌 토큰 수\n","    \n","    @staticmethod\n","    def make_std_mask(tgt, pad):\n","        \"Create a mask to hide padding and future words.\"\n","        tgt_mask = (tgt != pad).unsqueeze(-2) # (nbatches, 1, n_seq_trg)\n","        #tgt_mask = tgt_mask & Variable( subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data) )\n","        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n","        return tgt_mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ui_CyOaWfAzH"},"source":["`Batch`클래스는 입력 시퀀스와 타겟 시퀀스를 받아서 입력과 타겟의 마스크를 만들고 타겟을 디코더에 입력되는 타겟(`self.trg`)과 출력 타겟(`self.trg_y`)으로 분리합니다. 예를 들면 다음과 같습니다.\n","\n","- `src`: `I` `am` `a` `student.`\n","\n","- `trg`: `나는` `학생` `입니다.`\n","\n","    - `trg`: `나는` `학생`\n","    - `trg_y`: `학생` `입니다.`\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YN-7kibnl2zp"},"source":["다음으로 마스크를 만들게 되는데 마스크를 만드는 과정(`make_std_mask` 함수)은 코드만 봐서는 이해가 어려우므로 다음 예를 보면서 알아보겠습니다. \n","\n","이 글에서 어쩌면 가장 복잡하고 설명하기 지저분한 부분이니 잠시 쉬고 와서 읽도록 합시다. 😎"]},{"cell_type":"markdown","metadata":{"id":"eR2XCJltHa1F"},"source":["### Source mask (key pad mask)"]},{"cell_type":"markdown","metadata":{"id":"EJ2_DBN-l4xZ"},"source":["먼저 source mask에 대해서 알아봅시다. 아래 예에서는 시퀀스 길이 5인 샘플 두 개가 (2,5)인 행렬에 들어있는 상황입니다.\n","\n","예를 들어 각 샘플이 다음과 같다고 하겠습니다.\n","\n","*   `i,     love,  you,   [PAD],  [PAD]`\n","*   `good,  job,  [PAD],  [PAD],  [PAD]`\n","\n","이렇게 구성된 샘플에 셀프어텐션을 하는 경우 [PAD] 토큰에는 어텐션이 되면 안될 것입니다. 예를 들어 'i'와 관계가 있는 토큰을 알아내는 것이 셀프어텐션인데 그 후보 키 토큰에 [PAD]가 들어가는 것은 별로 바람직하지 않습니다. 물론 [PAD]가 쿼리로 작동하는 것도 피해야 합니다.따라서 [PAD] 가 있는 위치를 마스킹할 수 있는 마스크를 만들어야 합니다. \n","\n","마스크를 만들고 이를 직접 그림으로 보이는 것은 것은 트랜스포머 모델을 실제로 포워드 시켜야 하는 과정을 거쳐야 해서 매우 귀찮은 작업이지만 하나 하나 따라 가보도록 하겠습니다.😵\n","\n"," 단 문제를 단순화 하고 그림을 그리기 위해 헤드 하나를 가정합니다. \n","우선 모델과 관련된 변수를 적당히 세팅합니다.\n"]},{"cell_type":"code","metadata":{"id":"eT9KxTQaxhlI"},"source":["model_const = {'dv':3, 'dk':3, 'h':1, 'd_model':7, 'src_len':5, 'target_len':6}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdeZzzmpBfMo","executionInfo":{"status":"ok","timestamp":1636599310454,"user_tz":-540,"elapsed":253,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"be8b3009-5adf-4a12-bb58-ee9fa5537cef"},"source":["pad = 0\n","# 길이 7인 샘플 두 개, src:(2,5)\n","# 1번 샘플은 길이 5, 패딩 2, 예를 들어 i     love  you   [PAD]  [PAD]  \n","# 2번 샘플은 길이 2, 패딩 3, 예를 들어 good  job  [PAD]  [PAD]  [PAD]\n","# 임의 숫자를 토큰 번호로 가정하고 randint를 사용\n","src = torch.from_numpy(np.random.randint(1, 100, size=(2, model_const['src_len'])))\n","paddings = torch.LongTensor([2, 3]).reshape(-1,1) # 각 샘플당 패딩 개수\n","pad_idx = src.shape[1] - paddings\n","col_idx = torch.arange(src.shape[1]).reshape(1,-1)\n","# src = src * ~(paddings > col_idx)\n","src = src * (pad_idx > col_idx)\n","\n","# 마지막 토큰들은 PAD토큰이 되었음\n","print('src', src, '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["src tensor([[18, 89, 42,  0,  0],\n","        [92, 68,  0,  0,  0]]) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"rQPR8n5CBgnx"},"source":["이렇게 가상으로 만들어진 src에서 0인 자리를 `False`, 0이 아닌 자리를 `True`로 가지는 마스크를 생성합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VHv2zCgBrlS","executionInfo":{"status":"ok","timestamp":1636599312853,"user_tz":-540,"elapsed":261,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"931d4cdd-822b-43cf-9740-edf56fa0067d"},"source":["# (src != pad): (2,5)\n","# 패딩 토큰자리만 False인 src와 모양이 같은 마스크\n","print('\\n(src != pad).shape', (src != pad).shape)\n","print(src != pad, '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","(src != pad).shape torch.Size([2, 5])\n","tensor([[ True,  True,  True, False, False],\n","        [ True,  True, False, False, False]]) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"KxsUaK5kB2U0"},"source":["이제 멀티헤드 어텐션에 마스크를 적용하기 위해 중간 차원을 하나 더 늘립니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pGoHTIc6B688","executionInfo":{"status":"ok","timestamp":1636599315630,"user_tz":-540,"elapsed":266,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"724e70fb-92f5-4440-aba0-4081dd50467f"},"source":["src_mask_enc = (src != pad).unsqueeze(-2)\n","print('\\n(src != pad).unsqueeze(-2).shape:', src_mask_enc.shape)\n","print(src_mask_enc)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","(src != pad).unsqueeze(-2).shape: torch.Size([2, 1, 5])\n","tensor([[[ True,  True,  True, False, False]],\n","\n","        [[ True,  True, False, False, False]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"8bXmUJuNB8Vx"},"source":["결과는 (2,5)인 마스크가 (2,1,5)가 되는데 마스크가 적용될 시점의 코드를 다시보면 \n","\n","```python\n","# MultiHeadedAttention.forward()에서\n","    # Same mask applied to all h heads.\n","    mask = mask.unsqueeze(1)\n","    ...\n","    x, self.attn = attention(query, key, value, mask=mask, \n","                                 dropout=self.dropout)\n","\n","# attention()에서\n","    # scores: (nbatches, h, n_seq, n_seq)\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, -1e9)\n","```\n","\n","위 코드에서 `MultiHeadedAttention.forward()`를 거치면서 전달된 `src_mask`는 (2,1,5)가 (2,1,1,5)로 되며 이를 `(nbatches, h, n_seq, n_seq)`인 `score`에 적용하면 결국 h개 헤드에 행 방향으로만 마스크가 주어지게 됩니다. \n","\n","마스킹을 해서 그림을 그려보면\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":578},"id":"R7aixZgtDFpi","executionInfo":{"status":"ok","timestamp":1636599318480,"user_tz":-540,"elapsed":856,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"1c0e1f36-9443-44d7-c794-306bd74cc33b"},"source":["# 샘플 두개 헤드 하나짜리 (5,5)인 어텐션 스코어\n","encoder_self_attn_scores = torch.rand((2, 1, model_const['src_len'], \n","                                       model_const['src_len']))\n","src_mask_enc_reshape = src_mask_enc.unsqueeze(1)\n","\n","# -1e9로 마스킹을 하면 마스킹 되지 않는 부분이 모두 같은 색으로 \n","# 나타나므로 여기서는 그냥 0으로 마스킹\n","masked_encoder_self_attn_scores = encoder_self_attn_scores.masked_fill(\n","    src_mask_enc_reshape == 0, 0)\n","\n","fig, ax = plt.subplots(figsize=(12,5), nrows=1, ncols=2)\n","\n","ax[0].imshow(masked_encoder_self_attn_scores[0][0], cmap='BrBG')\n","ax[0].set_xticks([0, 1, 2, 3, 4])\n","ax[0].set_xticklabels(['i', 'love', 'you', '[PAD]', '[PAD]'], fontsize=15)\n","ax[0].set_xlabel('Key', fontsize=15)\n","ax[0].set_yticks([0, 1, 2, 3, 4])\n","ax[0].set_yticklabels(['i', 'love', 'you', '[PAD]', '[PAD]'], fontsize=15)\n","ax[0].set_ylabel('Query', fontsize=15)\n","ax[0].set_title('Sample 1', fontsize=15)\n","\n","ax[1].imshow(masked_encoder_self_attn_scores[1][0], cmap='BrBG')\n","ax[1].set_xticks([0, 1, 2, 3, 4])\n","ax[1].set_xticklabels(['good', 'job', '[PAD]', '[PAD]', '[PAD]'], fontsize=15)\n","ax[1].set_xlabel('Key', fontsize=15)\n","ax[1].set_yticks([0, 1, 2, 3, 4])\n","ax[1].set_yticklabels(['good', 'job', '[PAD]', '[PAD]', '[PAD]'], fontsize=15)\n","ax[1].set_ylabel('Query', fontsize=15)\n","ax[1].set_title('Sample 2', fontsize=15)\n","\n","plt.show()\n","\n","print(masked_encoder_self_attn_scores)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x360 with 2 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["tensor([[[[0.0488, 0.8163, 0.4423, 0.0000, 0.0000],\n","          [0.0960, 0.5537, 0.3953, 0.0000, 0.0000],\n","          [0.7403, 0.6766, 0.3798, 0.0000, 0.0000],\n","          [0.7709, 0.8970, 0.8421, 0.0000, 0.0000],\n","          [0.1475, 0.2248, 0.2086, 0.0000, 0.0000]]],\n","\n","\n","        [[[0.4891, 0.5210, 0.0000, 0.0000, 0.0000],\n","          [0.2097, 0.8500, 0.0000, 0.0000, 0.0000],\n","          [0.5633, 0.4963, 0.0000, 0.0000, 0.0000],\n","          [0.4965, 0.5638, 0.0000, 0.0000, 0.0000],\n","          [0.0942, 0.4641, 0.0000, 0.0000, 0.0000]]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"xLkGnGLkIMUb"},"source":["[PAD]에 해당하는 열만 마스킹되었습니다. 어텐션 스코어 행렬에서 행은 쿼리에, 열은 키에 해당하는데 이렇게 마스킹되는 것은 결국 키만 마스킹 했다는 의미입니다. 다시말해  i, love, you, [PAD], [PAD]라는 단어 다섯개에 대해서 유사도를 구해달라고 쿼리로 요청되었고 그에 대한 응답으로 [PAD] 두개는 마스킹하고 i, love, you만 키로해서 유사도를 구해준 것이죠. \n","\n","어차피 필요없는 [PAD]를 왜 쿼리로 요청했는지 의야할 수 있습니다. 그 이유는 이렇게 키만 마스킹된 인코딩 정보가 디코더로 넘어가 크로스 어텐션될 때는 다시 키로 작용하게 되는데 그때 키가 $K^T$로 전치 되면서 다시 한번 마스킹을 적용하면 마스킹 되지 않았던 쿼리에 대한 [PAD]도 마스킹되어 사라지기 때문입니다. \n","\n","이런 이유 때문에 이 소스코드에서 `src_mask`가 PyTorch에서는 `key_padding_mask`라는 이름으로 제공됩니다.\n","\n","> key_padding_mask: If specified, a mask of shape (N,S) indicating which elements within key to ignore for the purpose of attention (i.e. treat as  padding”). \n","\n","해당 과정은 설명의 마지막 부분에서 직접 코드로 확인하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"BqBQFZqwJl2X"},"source":["### Target mask"]},{"cell_type":"markdown","metadata":{"id":"Qwx0zM31Kvw5"},"source":["다음은 타겟쪽 마스크를 알아보겠습니다. 타겟 마스크도 먼저 [PAD] 위치를 마스킹 합니다. 이 과정은 앞서 알아본 `src_mask`와 동일합니다. 타겟 데이터는 소스가 번역된 다음 문장으로 가정합니다.\n","\n","\n","*   `나는,  당신을,  사랑,   합니다, [PAD], [PAD], [PAD]`\n","*   `잘,    했어,    [PAD],  [PAD],  [PAD], [PAD], [PAD]`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bp5FhIEkMMAS","executionInfo":{"status":"ok","timestamp":1636599673792,"user_tz":-540,"elapsed":266,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"612b9525-b3ad-4481-913b-ef39479de571"},"source":["# 디코더에 입력될 타겟을 준비한다. \n","# shape: (2,6)\n","# 임의 숫자를 토큰 번호로 가정하고 randint를 사용\n","trg = torch.from_numpy(np.random.randint(1, 100, size=(2, model_const['target_len'])))\n","paddings = torch.LongTensor([2, 4]).reshape(-1,1) # 각 샘플당 패딩 개수\n","pad_idx = trg.shape[1] - paddings\n","col_idx = torch.arange(trg.shape[1]).reshape(1,-1)\n","# src = src * ~(paddings > col_idx)\n","trg = trg * (pad_idx > col_idx)\n","\n","# 마지막 토큰들은 PAD토큰이 되었음\n","print('trg', trg, '\\n')\n","\n","# src때와 마찬가지로 패딩 토큰자리만 False인 trg와 모양이 같은 마스크\n","# shape: (2,6)\n","print('(trg != pad).shape', (trg != pad).shape)\n","print(trg != pad, '\\n')\n","\n","# src_mask때와 마찬가지로 차원을 늘린다.\n","# subsequent_mask()에서 출력된 마스크와 브로드캐스팅된다.\n","# (2,1,6)\n","print('(trg != pad).unsqueeze(-2).shape', (trg != pad).unsqueeze(-2).shape)\n","trg_mask = (trg != pad).unsqueeze(-2)\n","print(trg_mask, '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trg tensor([[29, 66, 61, 43,  0,  0],\n","        [59, 86,  0,  0,  0,  0]]) \n","\n","(trg != pad).shape torch.Size([2, 6])\n","tensor([[ True,  True,  True,  True, False, False],\n","        [ True,  True, False, False, False, False]]) \n","\n","(trg != pad).unsqueeze(-2).shape torch.Size([2, 1, 6])\n","tensor([[[ True,  True,  True,  True, False, False]],\n","\n","        [[ True,  True, False, False, False, False]]]) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"jLungGfHMtVr"},"source":["디코더 쪽에서 사용하는 타겟 마스크는 앞서 설명한 셀프 어텐션에 대한 마스킹도 함께 해야 하므로 `subsequnent_mask()`에서 생성된 마스크 행렬과 & 연산을 해줍니다."]},{"cell_type":"code","metadata":{"id":"VpgjuuMx7mWv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636600744418,"user_tz":-540,"elapsed":288,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"8fa5575b-242e-4e2c-f7ea-f2a9e9b3428e"},"source":["# 입력 타켓으로 subsequent_mask 마스크 행렬을 만든다.\n","# shape: (1, 6, 6)\n","self_attn_mask = subsequent_mask(trg.size(-1)).type_as(trg_mask.data)\n","print('self_attn_mask.shape => ', self_attn_mask.shape)\n","print( self_attn_mask, '\\n')\n","\n","# 패딩 토큰 자리가 False인 trg_mask와 subsequent_mask()의 결과를 & 한다.\n","# 다음 브로드캐스팅되는 과정이 있고 늘어나는 차원은 []로 표시했다.\n","# (2,1,6) & (1, 6, 6) => (2, [6], 6) & ([2], 6, 6)\n","trg_mask_dec = trg_mask & self_attn_mask\n","print('trg_mask_dec')    \n","print( trg_mask_dec )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["self_attn_mask.shape =>  torch.Size([1, 6, 6])\n","tensor([[[ True, False, False, False, False, False],\n","         [ True,  True, False, False, False, False],\n","         [ True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True]]]) \n","\n","trg_mask_dec\n","tensor([[[ True, False, False, False, False, False],\n","         [ True,  True, False, False, False, False],\n","         [ True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True, False, False]],\n","\n","        [[ True, False, False, False, False, False],\n","         [ True,  True, False, False, False, False],\n","         [ True,  True, False, False, False, False],\n","         [ True,  True, False, False, False, False],\n","         [ True,  True, False, False, False, False],\n","         [ True,  True, False, False, False, False]]])\n"]}]},{"cell_type":"code","metadata":{"id":"EtkQMCnMAoWX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dSoA3EJdnYx_"},"source":["위 코드의 주석을 읽고 마지막 출력 결과를 보면 패딩 토큰이 있는 행과 열은 모두 False이고 데이터가 있는 자리만 작게 하삼각 행렬이 True인 부분 행렬이 마스크로 만들어짐을 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"H158dtFsNhWq","executionInfo":{"status":"ok","timestamp":1636601438816,"user_tz":-540,"elapsed":856,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"20116805-79c9-4fac-ad6f-1a0380763ff0"},"source":["# 샘플 두개 헤드 하나짜리 (6,6)인 어텐션 스코어\n","decoder_self_attn_scores = torch.rand((2, 1, 6, 6))\n","trg_mask_dec_reshape = trg_mask_dec.unsqueeze(1)\n","\n","# -1e9로 마스킹을 하면 마스킹 되지 않는 부분이 모두 같은 색으로 \n","# 나타나므로 여기서는 그냥 0으로 마스킹\n","masked_decoder_self_attn_scores = decoder_self_attn_scores.masked_fill(trg_mask_dec_reshape == 0, 0)\n","\n","fig, ax = plt.subplots(figsize=(12,5), nrows=1, ncols=2)\n","\n","ax[0].imshow(masked_decoder_self_attn_scores[0][0], cmap='BrBG')\n","ax[0].set_xticks([0, 1, 2, 3, 4, 5])\n","ax[0].set_xticklabels(['나는', '당신을', '사랑', '합니다', '[PAD]', '[PAD]'], fontsize=15)\n","ax[0].set_xlabel('Key', fontsize=15)\n","ax[0].set_yticks([0, 1, 2, 3, 4, 5])\n","ax[0].set_yticklabels(['나는', '당신을', '사랑', '합니다', '[PAD]', '[PAD]'], fontsize=15)\n","ax[0].set_ylabel('Query', fontsize=15)\n","ax[0].set_title('Sample 1', fontsize=15)\n","\n","ax[1].imshow(masked_decoder_self_attn_scores[1][0], cmap='BrBG')\n","ax[1].set_xticks([0, 1, 2, 3, 4, 5])\n","ax[1].set_xticklabels(['잘', '했어', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], fontsize=15)\n","ax[1].set_xlabel('Key', fontsize=15)\n","ax[1].set_yticks([0, 1, 2, 3, 4, 5])\n","ax[1].set_yticklabels(['잘', '했어', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], fontsize=15)\n","ax[1].set_ylabel('Query', fontsize=15)\n","ax[1].set_title('Sample 2', fontsize=15)\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x360 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"5UZen0UQPYZE"},"source":["마스킹된 그림을 보면 셀프 어텐션에 대한 마스킹 때문에 상삼각행렬에 해당하는 요소가 모두 마스킹되었고 타겟에 있는 [PAD]에 대해서 열방향으로 마스킹 된 것을 확인할 수 있습니다.\n","\n","이제 마지막으로 디코더에서 일어나는 크로스 어텐션에 대한 마스크를 확인하도록 하겠습니다. 이를 위해 적당히 (nbatches=2, head=1, dv=5) 크기를 가지는 벨류 텐서를 만들고 앞서 소스 마스크에서 만들어 놓은 `masked_encoder_self_attn_scores` 텐서와 곱해 헤드를 만듭니다.\n","그 다음 임의로 초기화 된 $W^o$행렬과 곱해서 최종 인코딩을 만듭니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtYp3hvB17pN","executionInfo":{"status":"ok","timestamp":1636599749204,"user_tz":-540,"elapsed":484,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"fb7ce230-debf-4d25-d5ed-fe4c9e798205"},"source":["V = torch.rand((2, model_const['h'], model_const['src_len'], model_const['dv']))\n","# head가 하나 뿐이라 concat 할 필요없이 squeeze()합니다.\n","head = torch.matmul(masked_encoder_self_attn_scores, V).squeeze() \n","Wo = torch.rand(model_const['dv']*model_const['h'], model_const['d_model'])\n","encoding_src = torch.matmul(head, Wo)\n","\n","print(encoding_src.shape)\n","print(encoding_src)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 5, 7])\n","tensor([[[1.3157, 0.8231, 1.8169, 2.2399, 0.7467, 0.7838, 0.9017],\n","         [1.0317, 0.6436, 1.4306, 1.7503, 0.5839, 0.5992, 0.7001],\n","         [1.7735, 1.1149, 2.3128, 2.7675, 1.1070, 0.8919, 1.2505],\n","         [2.4297, 1.5170, 3.2814, 3.9383, 1.4432, 1.2764, 1.6642],\n","         [0.5630, 0.3511, 0.7676, 0.9250, 0.3292, 0.3033, 0.3835]],\n","\n","        [[0.7225, 0.4850, 0.8106, 1.1491, 0.5061, 0.5566, 0.6293],\n","         [0.7500, 0.5038, 0.8479, 1.2112, 0.5195, 0.5941, 0.6536],\n","         [0.7592, 0.5096, 0.8507, 1.2044, 0.5327, 0.5821, 0.6612],\n","         [0.7580, 0.5088, 0.8508, 1.2065, 0.5306, 0.5848, 0.6602],\n","         [0.3948, 0.2652, 0.4466, 0.6385, 0.2731, 0.3136, 0.3440]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Lvg7w2qh2DLM"},"source":["이렇게 만들어진 인코딩에서 4행과 5행은 [PAD]가 인코딩된 정보임을 상기 합시다. 이제 디코더 쪽에서 타겟에 대한 인코딩을 동일한 방식으로 만듭니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwQw-5dG2aSW","executionInfo":{"status":"ok","timestamp":1636599757942,"user_tz":-540,"elapsed":282,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"3599cdb3-0686-421a-ce00-ad64bb47cd2b"},"source":["V = torch.rand((2, 1, model_const['target_len'], model_const['dv']))\n","head = torch.matmul(masked_decoder_self_attn_scores, V).squeeze()\n","Wo = torch.rand(model_const['dv']*model_const['h'], model_const['d_model'])\n","encoding_trg = torch.matmul(head, Wo)\n","\n","print(encoding_trg.shape)\n","print(encoding_trg)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 6, 7])\n","tensor([[[0.1092, 0.2553, 0.2908, 0.3739, 0.3702, 0.1855, 0.0366],\n","         [0.6836, 1.0122, 1.1891, 1.4366, 1.6190, 0.8272, 0.2952],\n","         [0.2467, 0.5165, 0.5903, 0.7477, 0.7585, 0.3868, 0.0951],\n","         [1.0650, 1.6200, 1.7648, 1.9914, 2.1176, 1.4748, 0.8864],\n","         [1.5561, 2.6366, 2.8497, 3.2805, 3.3495, 2.3318, 1.3270],\n","         [0.8810, 1.3566, 1.5207, 1.7734, 1.9178, 1.1775, 0.5928]],\n","\n","        [[0.5224, 0.7097, 0.7051, 0.6843, 0.7026, 0.7583, 0.6666],\n","         [0.3033, 0.5964, 0.5850, 0.6280, 0.5492, 0.5731, 0.4405],\n","         [0.5860, 0.8012, 0.7957, 0.7740, 0.7920, 0.8543, 0.7493],\n","         [0.2773, 0.5113, 0.5024, 0.5316, 0.4760, 0.4994, 0.3928],\n","         [1.1601, 1.9902, 1.9602, 2.0378, 1.8777, 1.9823, 1.6005],\n","         [0.7322, 1.0746, 1.0643, 1.0591, 1.0460, 1.1204, 0.9576]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ab_t0pHC2oRj"},"source":["이제 `encoding_src`를 키와 벨류로 사용하고 `encoding_trg`를 쿼리로 사용해서 어텐션합니다. 이때 어텐션 마스크는 소스 마스크인 `src_mask_enc_reshape`를 사용합니다.\n","\n","`encoding_src`와 `encoding_trg`가 `MultiHeadedAttention.forward()`로 입력되면 앞서 알아본과정을 통해 이 인코딩들도 멀티헤드 쿼리, 키, 벨류로 바뀌게 됩니다. 여기서는 이 과정을 거쳤다고 가정하고 바로 텐서를 (nbatches, h, n_seq, d_k)로 변환하여 사용하겠습니다.\n","\n","변환된 두 인코딩 텐서를 어텐션 연산하고 마스크를 적용합니다.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw_GcUc070oN","executionInfo":{"status":"ok","timestamp":1636599763006,"user_tz":-540,"elapsed":253,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"262f7f98-5772-4eda-c3eb-5af9e8f52198"},"source":["multiheaded_encoding_src = encoding_src.unsqueeze(1)\n","multiheaded_encoding_trg = encoding_trg.unsqueeze(1)\n","\n","cross_QKt = torch.matmul(multiheaded_encoding_trg, \n","                         multiheaded_encoding_src.transpose(3,2))\n","\n","print('cross_QKt shape =>', cross_QKt.shape)\n","print(cross_QKt)\n","\n","masked_cross_QKt = cross_QKt.masked_fill(src_mask_enc_reshape == 0, 0)\n","print(masked_cross_QKt)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cross_QKt shape => torch.Size([2, 1, 6, 5])\n","tensor([[[[ 2.1746,  1.7004,  2.8068,  3.9115,  0.9124],\n","          [ 9.2343,  7.2198, 11.9659, 16.6396,  3.8791],\n","          [ 4.4522,  3.4812,  5.7513,  8.0110,  1.8685],\n","          [13.9381, 10.8922, 18.0558, 25.0925,  5.8496],\n","          [22.2684, 17.4027, 28.8159, 40.0696,  9.3428],\n","          [11.9004,  9.3017, 15.4144, 21.4298,  4.9960]]],\n","\n","\n","        [[[ 3.2766,  3.4272,  3.4387,  3.4388,  1.8053],\n","          [ 2.5783,  2.6983,  2.7056,  2.7060,  1.4214],\n","          [ 3.6942,  3.8640,  3.8769,  3.8770,  2.0354],\n","          [ 2.2324,  2.3361,  2.3427,  2.3429,  1.2306],\n","          [ 8.7947,  9.2023,  9.2293,  9.2301,  4.8475],\n","          [ 4.8854,  5.1106,  5.1270,  5.1272,  2.6920]]]])\n","tensor([[[[ 2.1746,  1.7004,  2.8068,  0.0000,  0.0000],\n","          [ 9.2343,  7.2198, 11.9659,  0.0000,  0.0000],\n","          [ 4.4522,  3.4812,  5.7513,  0.0000,  0.0000],\n","          [13.9381, 10.8922, 18.0558,  0.0000,  0.0000],\n","          [22.2684, 17.4027, 28.8159,  0.0000,  0.0000],\n","          [11.9004,  9.3017, 15.4144,  0.0000,  0.0000]]],\n","\n","\n","        [[[ 3.2766,  3.4272,  0.0000,  0.0000,  0.0000],\n","          [ 2.5783,  2.6983,  0.0000,  0.0000,  0.0000],\n","          [ 3.6942,  3.8640,  0.0000,  0.0000,  0.0000],\n","          [ 2.2324,  2.3361,  0.0000,  0.0000,  0.0000],\n","          [ 8.7947,  9.2023,  0.0000,  0.0000,  0.0000],\n","          [ 4.8854,  5.1106,  0.0000,  0.0000,  0.0000]]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"od8KVLXs7-al"},"source":["적용된 결과를 그려보면..."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"vyMHxfrFPtRf","executionInfo":{"status":"ok","timestamp":1636599784644,"user_tz":-540,"elapsed":315,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"9d36a37c-0716-424a-bcf4-c94c51f10fec"},"source":["fig, ax = plt.subplots(figsize=(12,5), nrows=1, ncols=2)\n","\n","ax[0].imshow(masked_cross_QKt[0][0], cmap='BrBG')\n","ax[0].set_xticks([0, 1, 2, 3, 4])\n","ax[0].set_xticklabels(['i', 'love', 'you', '[PAD]', '[PAD]'], fontsize=15)\n","ax[0].set_xlabel('Key', fontsize=15)\n","ax[0].set_yticks([0, 1, 2, 3, 4, 5])\n","ax[0].set_yticklabels(['나는', '당신을', '사랑', '합니다', '[PAD]', '[PAD]'], fontsize=15)\n","ax[0].set_ylabel('Query', fontsize=15)\n","ax[0].set_title('Sample 1', fontsize=15)\n","\n","ax[1].imshow(masked_cross_QKt[1][0], cmap='BrBG')\n","ax[1].set_xticks([0, 1, 2, 3, 4])\n","ax[1].set_xticklabels(['go', 'job',  '[PAD]', '[PAD]', '[PAD]'], fontsize=15)\n","ax[1].set_xlabel('Key', fontsize=15)\n","ax[1].set_yticks([0, 1, 2, 3, 4, 5])\n","ax[1].set_yticklabels(['잘', '했어', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], fontsize=15)\n","ax[1].set_ylabel('Query', fontsize=15)\n","ax[1].set_title('Sample 2', fontsize=15)\n","\n","plt.show()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x360 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"-6jm3HXj8DN-"},"source":["드디어 😲 타겟의 쿼리 '나는', '당신을', '사랑', '합니다', '[PAD]', '[PAD]'가 소스쪽 키 'i', 'love', 'you'와 어텐션되는 것을 확인할 수 있습니다! 인코더에서 [PAD]가 인코딩되어 온 정보는 디코더쪽 크로스 어텐션에서 비로소 패딩되어 사라지는 것을 확인할 수 있습니다.\n","\n","<a name=\"cell-id-targetmask\"></a>\n","그럼 쿼리로 쓰이는 타겟에 포함된 [PAD]는 언제 마스킹 될까요? 이 [PAD]는 로스를 계산할 때 마스킹되게 됩니다. 그 과정이 아래쪽 [Label Smoothing](#cell-id-labelsmoothing) 절에 나와 있습니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-ZjtZBy_-Pah"},"source":["## Coffe Break\n","\n","트랜스포머를 이해하는데 있어 매우 귀찮은 마스킹을 완전히 분석했습니다. 여기까지 읽고 내용을 머리에 그릴 수 있다면 이제 글을 더 읽지 말고 커피나 음료수를 마시면서 쉬도록 합시다. 나머지는 내일 읽어주셔도 됩니다. 😁"]},{"cell_type":"markdown","metadata":{"id":"RJcN5-zm_MiL"},"source":["## 장난감 데이터 생성함수"]},{"cell_type":"markdown","metadata":{"id":"WoncHyDrbpUM"},"source":["원문에서는 아래 함수처럼 입력과 출력이 동일한 무작위 숫자를 열개 생성하여 입력이 들어갔을 때 제대로 출력이 나오는지 체크합니다."]},{"cell_type":"code","metadata":{"id":"9qffH6rN0lpl"},"source":["def data_gen(V, batch, nbatches):\n","    \"Generate random data for a src-tgt copy task.\"\n","    for i in range(nbatches):\n","        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n","        data[:, 0] = 1\n","        src = data; src.requires_grad=False\n","        tgt = data; tgt.requires_grad=False\n","        yield Batch(src, tgt, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h78nlMpkd6Fl"},"source":["입력과 동일한 출력이 나오는 예제는 너무 재미가 없으니 여기서는 이 예제를 살짝 바꿔서 길이 10짜리 무작위 숫자를 입력으로 사용하는 것은 똑같으나 출력은 5번부터 10번 숫자 즉 뒤쪽 절반에 +1을 한 것을 출력으로 설정하겠습니다.\n","\n","예를 들면 다음과 같습니다.\n","\n","```\n","- 입력: 1 2 3 4 5 6 7 8  9 10\n","- 출력: 1 2 3 4 5 7 8 9 10 11\n","```"]},{"cell_type":"markdown","metadata":{"id":"hKIKnFeQBFqV"},"source":["간단하게 데이터를 생성하는 함수를 만듭니다."]},{"cell_type":"code","metadata":{"id":"5Ck0GGgOTSiA"},"source":["def data_gen2(V, batch, nbatches):\n","    \"\"\"\n","    무작위 데이터를 생성하는데\n","    데이터 길이의 뒷 절반에 +1 한 것이 정답 벡터인 데이터를 생성한다.\n","    V: 단어장에 단어수\n","    batch: 한 미니배치에 샘플 수\n","    nbatches: 한 에폭에 있는 미니배치 수\n","    \"\"\"\n","    for i in range(nbatches):\n","        # 샘플하나당 시퀀스 길이는 10으로 고정\n","        data = torch.from_numpy(np.random.randint(1, V-1, size=(batch, 10)))\n","        data.requires_grad = False\n","        data[:, 0] = 1\n","        \n","        src = data.clone() \n","        tgt = data.clone()\n","        # 뒤에 다섯개는 +1\n","        tgt[:, V//2:] +=1 \n","        \n","        yield Batch(src, tgt, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nf-ZS8TsThrC","executionInfo":{"status":"ok","timestamp":1636516550969,"user_tz":-540,"elapsed":12,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"07ad4297-36df-4792-d32b-a7b045a3601b"},"source":["# data_gen2가 제대로 작동하는지 확인\n","# 단어수: 11, 미니배치사이즈:1, 에폭당 미니배치:10\n","for data in data_gen2(11, 1, 10) :\n","    # 입력, teach_forcing의 입력, teach_forcing의 출력\n","    print('data.src: ', data.src)\n","    print('data.src_mask: ', data.src_mask)\n","    print('data.trg: ', data.trg)\n","    print('data.trg_y: ', data.trg_y)\n","    print('data.trg_mask\\n', data.trg_mask)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data.src:  tensor([[1, 8, 3, 4, 5, 2, 6, 1, 6, 4]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[1, 8, 3, 4, 5, 3, 7, 2, 7]])\n","data.trg_y:  tensor([[8, 3, 4, 5, 3, 7, 2, 7, 5]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 5, 4, 1, 2, 9, 4, 8, 6, 7]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[ 1,  5,  4,  1,  2, 10,  5,  9,  7]])\n","data.trg_y:  tensor([[ 5,  4,  1,  2, 10,  5,  9,  7,  8]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 5, 2, 1, 7, 3, 7, 3, 8, 7]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[1, 5, 2, 1, 7, 4, 8, 4, 9]])\n","data.trg_y:  tensor([[5, 2, 1, 7, 4, 8, 4, 9, 8]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 3, 8, 3, 8, 6, 5, 3, 7, 7]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[1, 3, 8, 3, 8, 7, 6, 4, 8]])\n","data.trg_y:  tensor([[3, 8, 3, 8, 7, 6, 4, 8, 8]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 2, 7, 4, 8, 8, 7, 9, 1, 5]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[ 1,  2,  7,  4,  8,  9,  8, 10,  2]])\n","data.trg_y:  tensor([[ 2,  7,  4,  8,  9,  8, 10,  2,  6]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 3, 3, 4, 4, 2, 3, 1, 3, 9]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[1, 3, 3, 4, 4, 3, 4, 2, 4]])\n","data.trg_y:  tensor([[ 3,  3,  4,  4,  3,  4,  2,  4, 10]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 4, 2, 9, 9, 9, 9, 7, 1, 2]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[ 1,  4,  2,  9,  9, 10, 10,  8,  2]])\n","data.trg_y:  tensor([[ 4,  2,  9,  9, 10, 10,  8,  2,  3]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 4, 2, 7, 4, 6, 2, 1, 5, 6]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[1, 4, 2, 7, 4, 7, 3, 2, 6]])\n","data.trg_y:  tensor([[4, 2, 7, 4, 7, 3, 2, 6, 7]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 4, 4, 4, 1, 6, 9, 3, 4, 9]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[ 1,  4,  4,  4,  1,  7, 10,  4,  5]])\n","data.trg_y:  tensor([[ 4,  4,  4,  1,  7, 10,  4,  5, 10]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","data.src:  tensor([[1, 8, 8, 5, 3, 3, 4, 3, 4, 9]])\n","data.src_mask:  tensor([[[True, True, True, True, True, True, True, True, True, True]]])\n","data.trg:  tensor([[1, 8, 8, 5, 3, 4, 5, 4, 5]])\n","data.trg_y:  tensor([[ 8,  8,  5,  3,  4,  5,  4,  5, 10]])\n","data.trg_mask\n"," tensor([[[ True, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"WmQJGmokef8j"},"source":["미니배치 내 샘플들을 최대 길이로 잘라주는 함수입니다."]},{"cell_type":"code","metadata":{"id":"egTWNxnQ0LRX"},"source":["global max_src_in_batch, max_tgt_in_batch\n","def batch_size_fn(new, count, sofar):\n","    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n","    global max_src_in_batch, max_tgt_in_batch\n","    if count == 1:\n","        max_src_in_batch = 0\n","        max_tgt_in_batch = 0\n","    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n","    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n","    src_elements = count * max_src_in_batch\n","    tgt_elements = count * max_tgt_in_batch\n","    return max(src_elements, tgt_elements)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JoTf84tRMNLq"},"source":["## Learning Rate Warm Up"]},{"cell_type":"markdown","metadata":{"id":"uakqnXcbJbJM"},"source":["$$\n","lrate = d^{-0.5}_{\\text{model}}\\cdot \\min \\left({step\\_num}^{-0.5}, {step\\_num} \\cdot  {warmup\\_steps}^{-1.5} \\right)\n","$$\n","\n","학습중 학습률을 위 식처럼 변경합니다. 식에서 $step\\_num$은 옵티마이저가 파라미터를 한번 업데이트할 때마다 1 증가하는 진행 스탭수를 나타냅니다. 학습 초기에는 $step\\_num$이 작기 때문에 다음과 같습니다.\n","\n","$$\n","{step\\_num} \\cdot  {warmup\\_steps}^{-1.5} = \\min \\left({step\\_num}^{-0.5}, {step\\_num} \\cdot  {warmup\\_steps}^{-1.5} \\right)\n","$$\n","\n","즉 $step\\_num$이 증가함에 따라 선형적으로 학습률이 증가합니다. $step\\_num$이 계속 증가하다가 $step\\_num =  warmup\\_steps$가 되면 $\\min$ 안에 두 항은 같아지게 되고 그 다음 스탭부터 \n","\n","$$\n","{step\\_num}^{-0.5} = \\min \\left({step\\_num}^{-0.5}, {step\\_num} \\cdot  {warmup\\_steps}^{-1.5} \\right)\n","$$\n","\n","가 되어 $step\\_num$의 제곱에 반비례하게 학습률이 천천히 줄어들게 됩니다. 코드를 보면 전체적으로 학습률의 크기를 조정하기 위해 모델 사이즈와 별도의 factor를 곱하는 것을 확인할 수 있습니다.\n"]},{"cell_type":"code","metadata":{"id":"s_LTh2Cm0NGb"},"source":["class NoamOpt:\n","    \"Optim wrapper that implements rate.\"\n","    def __init__(self, model_size, factor, warmup, optimizer):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.warmup = warmup\n","        self.factor = factor\n","        self.model_size = model_size\n","        self._rate = 0\n","        \n","    def step(self):\n","        \"Update parameters and rate\"\n","        self._step += 1\n","        rate = self.rate()\n","        for p in self.optimizer.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","        self.optimizer.step()\n","        \n","    def rate(self, step = None):\n","        \"Implement `lrate` above\"\n","        if step is None:\n","            step = self._step\n","        # 초기에는 min( , )에서 뒷부분이 작동하여 step에 선형적으로 lr이 증가\n","        # 그렇게 뒷 부분이 자꾸 커지다 step에 self.warmup과 같아지면\n","        # 뒷부분이 step*step**(-1.5)=step**(-0.5)가 되고 \n","        # step = self.warmup+1부터는 앞부분이 작아져서\n","        # 어느 순간 step의 제곱근에 반비례하게 lr이 줄어듬\n","        return self.factor * \\\n","            (self.model_size ** (-0.5) * \n","             min(step ** (-0.5), step * self.warmup ** (-1.5)))\n","        \n","def get_std_opt(model):\n","    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n","            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Pbnvo2ye7xl"},"source":["모델 사이즈 512, 256, 웜업스탭 4000, 8000인 경우에 대해서 학습률이 어떻게 변화하는지 그래프로 그리면 아래와 같습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"V-y_OLgv0PQQ","executionInfo":{"status":"ok","timestamp":1636516550970,"user_tz":-540,"elapsed":11,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"f100d12f-eb36-4c49-f9d0-df70097ee20a"},"source":["opts = [NoamOpt(512, 1, 4000, None), \n","        NoamOpt(512, 1, 8000, None),\n","        NoamOpt(256, 1, 4000, None)]\n","plt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\n","plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f77f70dbe10>"]},"metadata":{},"execution_count":50},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ZsOLpNcrKSH_"},"source":["<a name=\"cell-id-labelsmoothing\"></a>\n","## Label Smoothing\n","\n","예측을 할 때 정답이라고 예측된 토큰에 거의 확률 1로 예측하는 것을 막기위해 레이블을 깍아주는 작업을 하면 예측 성능이 더 좋아지는 것으로 알려져 있습니다.\n","\n","아래 원문처럼 0, 1로 구성된 확률 분포를 정답 분포로 쓰지 않고 정답자리 확률을 0.8정도로 깍아내리고 깍아낸 0.2를 나머지 오답 자리에 고루 분배하여 정답 분포를 마치 '신뢰도'정도로 해석할 수 있게 하는 방식입니다.\n","\n","> We implement label smoothing using the KL div loss. Instead of using a one-hot target distribution, we create a distribution that has `confidence` of the correct word and the rest of the `smoothing` mass distributed throughout the vocabulary."]},{"cell_type":"code","metadata":{"id":"_uYddYnl0R24"},"source":["class LabelSmoothing(nn.Module):\n","    \"Implement label smoothing.\"\n","    def __init__(self, size, padding_idx, smoothing=0.0):\n","        super(LabelSmoothing, self).__init__()\n","        \n","        # size_average and reduce are in the process of being deprecated, \n","        # and in the meantime, specifying either of those two args will override reduction.\n","        # self.criterion = nn.KLDivLoss(size_average=False)\n","        \n","        # smoothing을 적용한 타겟과 로스를 구하므로 NLLLoss 대신 KLDivLoss 사용\n","        self.criterion = nn.KLDivLoss(reduction='sum') # input: log-probabilities \n","        self.padding_idx = padding_idx\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.size = size\n","        self.true_dist = None\n","        \n","    def forward(self, x, target):\n","        # x: model.generator에서 출력한 log_softmax 값\n","\n","        assert x.size(1) == self.size\n","        true_dist = x.data.clone()\n","        true_dist.fill_(self.smoothing / (self.size - 2)) # 정답자리와 패딩자리 두자리 빼고\n","        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        # 여기까지 스무딩 시켰고...\n","        \n","        # 패딩 토큰 위치는 확률을 0으로 지정\n","        true_dist[:, self.padding_idx] = 0\n","        \n","        # target이 패팅토큰 번호라면 그 데이터에 대해서는 로스를 구할 필요\n","        # 없으므로 모든 확률분포자리를 0으로 만들어 버림\n","        mask = torch.nonzero(target.data == self.padding_idx)\n","        if mask.dim() > 0:\n","            # index_fill_(dim, index, val): dim차원을 따라 index가 지정된 위치에 val을 채움\n","            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","        self.true_dist = true_dist\n","\n","        # loss 계산\n","        return self.criterion(x, true_dist)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QcTg7E9WhaFS"},"source":["늘 그렇듯이 위 코드를 보면 또 이해가 쉽지 않습니다. 그래서 하나씩 뜯어서 알아보도록 하겠습니다. 간단한 예제를 위해 단어장 크기가 5라고 가정하겠습니다. `smoothing=0.4`로 두면 다음처럼 시작할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"0RCnP1R-h-fj"},"source":["size = 5\n","smoothing = 0.4\n","# 정답자리가 가져갈 확률 원래는 1인데 (1-smoothing)으로 깍아버리고\n","# 깍은 만큼(smoothing)을 오답자리에 동일하게 나눠 주는 작업을 시작\n","confidence = 1- smoothing \n","padding_idx = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ofZSXUIGh_iG"},"source":["총 세 개 샘플에 대해서 다음처럼 예측이 나왔다고 하겠습니다."]},{"cell_type":"code","metadata":{"id":"5cgZHQnTiGmy"},"source":["# 예측은 2번, 2번, 2번 토큰으로 예측\n","# 총 다섯개의 토큰이 있고 0번 토큰은 [PAD], 1~4번 토큰은 일반 토큰\n","#              토큰위치 0    1    2    3   4  \n","x = torch.FloatTensor([[0, 0.2, 0.7, 0.1,  0],\n","                       [0, 0.2, 0.7, 0.1,  0], \n","                       [0, 0.2, 0.7, 0.1,  0]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mAZUZHbhiHmi"},"source":["세 개 샘플에 대해서 모두 2번 단어가 정답이라고 예측한 상황입니다. 그리고 정답 타겟은 (2, 0, 0)이라고 가정하겠습니다. 측 첫 샘플만 2번 단어가 정답이고 나머지 뒤 두개는 패딩 토큰인 상황입니다. 각 샘플에 대한 정답 분포르 만듭니다. 원래 정답분포는 다음과 같아야 하지만\n","\n","$$\n","\\begin{bmatrix}\n","0 & 0& 1& 0& 0 \\\\\n","1& 0& 0& 0& 0 \\\\\n","1& 0& 0& 0& 0 \\\\\n","\\end{bmatrix}\n","$$\n","\n","smoothing을 통해 어떻게 변하는지 확인해보기로 합시다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bMrGF-bzif03","executionInfo":{"status":"ok","timestamp":1636516551578,"user_tz":-540,"elapsed":17,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"3c3a61dc-bd1e-4227-c810-fb446121f835"},"source":["# 타겟은 2, 0, 0\n","target  = torch.LongTensor([2,0,0])\n","true_dist = x.clone()\n","\n","# 정답1개, 패딩1개 해서 -2\n","# 여기서 smoothing을 정답과 패딩 토큰 위치를 제외한 나머지 토큰들에게\n","# 나눠준다.\n","true_dist.fill_(smoothing / (size-2)) \n","\n","# 정답자리에는 confidence, 여기선 0.6을 대입\n","#                  1번축을 따라\n","#                     이 인덱스에 해당하는 위치에\n","#                                               confidence값을 대입\n","true_dist.scatter_(1, target.data.unsqueeze(1), confidence)\n","print(true_dist)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1333, 0.1333, 0.6000, 0.1333, 0.1333],\n","        [0.6000, 0.1333, 0.1333, 0.1333, 0.1333],\n","        [0.6000, 0.1333, 0.1333, 0.1333, 0.1333]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"MHYVZagonvcG"},"source":["계산된 `true_dist`는 원래 정답분포가 0인 자리에 `(1-smoothing) / 3`값이 들어가고 1인 자리에 `smoothing`값이 들어간것을 확인할 수 있습니다.\n","\n","이제 나머지 작업을 수행합니다. 패딩 토큰에 0.6이라는 확률이 부여 되어 있는데 패딩 토큰은 예측할 일이 없으니 0으로 만듭니다. 그리고 정답이 패딩토큰인 샘플은 모든 자리를 0으로 만들어 버립니다. \n","\n","[Target mask] 절에서 최종적으로 마스킹된 결과에 디코더에서 입력된 [PAD] 토큰 위치는 마스킹하지 않고 그대로 둔 것이 기억 나시나요? 기억이 잘나지 않으면 [여기](#cell-id-targetmask)를 클릭해서 다시 돌아가봅시다. \n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnMJSkfLVVm5","executionInfo":{"status":"ok","timestamp":1636516551579,"user_tz":-540,"elapsed":17,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"5dc23e08-14e2-493e-fc3c-d5e8b0b1749c"},"source":["# 예측 벡터의 길이는 단어장 단어 개수와 같은데 \n","# 패딩 토큰은 예측할 일이 없으니 패딩 토큰 자리는 확률을 0으로 지정\n","true_dist[:, padding_idx] = 0 \n","print(true_dist)\n","\n","# target이 패딩되어 있어서 (타겟도 시퀀스니까 미니배치 안에서 패딩될 수 있음)\n","# [2, padding_idx, padding_idx]처럼 target이 생겼는데\n","# target에서 padding_idx가 나타나는 위치에 예측 벡터는 모조리 0으로 채움\n","# 이렇게 하면 2번, 3번 데이터는 로스 계산에서 빠짐\n","# torch.nonzero(..., as_tuple=False) \n","# (default) returns a 2-D tensor where each row is the index for a nonzero value.\n","print(target.data == padding_idx)\n","mask = torch.nonzero(target.data == padding_idx) # 정답이 패딩인덱스와 같은 데이터 번호\n","print(mask)\n","print(mask.squeeze())\n","\n","# index_fill_(dim, index, val): dim차원을 따라 index가 지정된 위치에 val을 채움\n","true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","print(true_dist)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],\n","        [0.0000, 0.1333, 0.1333, 0.1333, 0.1333],\n","        [0.0000, 0.1333, 0.1333, 0.1333, 0.1333]])\n","tensor([False,  True,  True])\n","tensor([[1],\n","        [2]])\n","tensor([1, 2])\n","tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"zn2mlSOmKccL"},"source":["마지막에 출력된 결과 텐서를 보면 1행만 smoothing된 확률분포가 들어있고 [PAD] 토큰에 해당하는 2, 3행은 모두 0으로 채워진 것을 볼 수 있습니다. 이렇게 해서 마스킹에 대한 세부 사항이 모두 정리가 되었습니다. 🥳\n","\n","위 `LabelSmoothing` 클래스는 이 코드들을 하나로 묶에 놓은 것입니다.  `LabelSmoothing`클래스를 이용해서 실제로 smoothing하는 예제가 아래 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403},"id":"NnWsqjC20UyS","executionInfo":{"status":"ok","timestamp":1636516551580,"user_tz":-540,"elapsed":14,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"ff3b8712-b37e-4cca-9e2f-a2398c773d1e"},"source":["# Example of label smoothing.\n","# 단어장 크기가 5인데 0번 단어는 패딩토큰\n","crit1 = LabelSmoothing(5, 0, 0.0)\n","crit2 = LabelSmoothing(5, 0, 0.4)\n","\n","# 예측은 2번, 2번, 2번 토큰으로 예측\n","# 총 다섯개의 토큰이 있고 0번 토큰은 [PAD], 1~4번 토큰은 일반 토큰\n","#                    토큰위치 0    1    2    3   4  \n","predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1,  0],\n","                             [0, 0.2, 0.7, 0.1,  0], \n","                             [0, 0.2, 0.7, 0.1,  0]])\n","# 정답은 2번, 1번, 0번, 즉 마지막 단어는 패딩토큰이 정답이라면\n","v1 = crit1(predict.log(), torch.LongTensor([2, 1, 0]))\n","v2 = crit2(predict.log(), torch.LongTensor([2, 1, 0]))\n","\n","# Show the target distributions expected by the system.\n","# 결과를 보면 패딩토큰 자리는 모두 0 (1번 열)\n","# target에서 패딩된 단어에 해당하는 예측 3행은 모든 자리가 0\n","fig, ax = plt.subplots(figsize=(10,5), nrows=1, ncols=2)\n","\n","ax[0].set_title(\"Distribution of target without smoothing\")\n","print(crit1.true_dist)\n","ax[0].imshow(crit1.true_dist)\n","\n","ax[1].set_title(\"Distribution of target with smoothing\")\n","print(crit2.true_dist)\n","ax[1].imshow(crit2.true_dist)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 1., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]])\n","tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],\n","        [0.0000, 0.6000, 0.1333, 0.1333, 0.1333],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 8722 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 8722 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"fTVzkFiaKfPV"},"source":["`LabelSmoothing` 클래스에서 정답 분포를 smoothing하고 나서 로스 까지 계산하므로 정답자리에 대한 확신이 점점 1에 가까워지면 로스가 어떻게 계산되는지 확인해볼 수 있습니다.\n","\n",">Label smoothing actually starts to penalize the model if it gets very confident about a given choice.\n","\n","아래 코드셀에서 `x`가 커지면 `x/d`가 점점 1에 가깝게 되고 그렇게 되면 로스 값이 조금씩 증가하는 것을 볼 수 있습니다."]},{"cell_type":"code","metadata":{"id":"mH9l5qAF0WSn","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1636516552017,"user_tz":-540,"elapsed":448,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"7178fa3a-648a-4fdf-c4db-df203d074a6d"},"source":["crit = LabelSmoothing(5, 0, 0.1)\n","def loss(x):\n","    d = x + 3 * 1\n","\n","    predict = torch.FloatTensor([[0, x/d, 1/d, 1/d, 1/d]])\n","    \n","    return crit(predict.log(), torch.LongTensor([1]))#.data[0]\n","\n","plt.plot(np.arange(1, 100), [loss(x) for x in range(1, 100)])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f77f6f47d90>]"]},"metadata":{},"execution_count":57},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"FF3cdO9M0HM4"},"source":["## Loss 계산\n","\n","`LabelSmoothing`에서 smoothing 뿐만 아니라 `nn.KLDivLoss`를 사용해서 로스값을 계산합니다. 원래 정답분포는 정답자리만 1이고 나머지는 모두 0입니다. 이럴 때 주로 사용하는 손실함수는 `nn.NLLLoss`입니다. 하지만 `LabelSmoothing`이 정답분포를 부드럽게 깍았으므로 모든 오답자리에도 확률이 할당되어 있습니다. 이럴때 출력분포와 정답분포의 차이를 계산하기 위해 Kullback–Leibler divergence[[7](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)]를 사용합니다. `SimpleLossCompute`는 `model.generator`를 호출해서 모델의 출력값을 계산한다음 그 값을 `LabelSmoothing`에 넘겨 로스값을 받아오고 백워드까지 수행합니다."]},{"cell_type":"code","metadata":{"id":"SFQKwCOT1MLH"},"source":["class SimpleLossCompute:\n","    \"A simple loss compute and train function.\"\n","    def __init__(self, generator, criterion, opt=None):\n","        # 여기서 generator는 model.generator\n","        self.generator = generator\n","        \n","        # 여기서 criterion은 LabelSmoothing \n","        self.criterion = criterion\n","\n","        self.opt = opt\n","        \n","    def __call__(self, x, y, norm):\n","        # norm은 batch에서 토큰 수\n","        # self.ntokens = (self.trg_y != pad).data.sum() # 패딩 토큰이 아닌 토큰 수\n","        \n","        x = self.generator(x)\n","        \n","        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n","                              y.contiguous().view(-1)) / norm\n","        loss.backward()\n","        if self.opt is not None:\n","            self.opt.step()\n","            self.opt.optimizer.zero_grad()\n","        # return loss.data[0] * norm\n","        return loss * norm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q3trxirYgDG0"},"source":["## 학습\n","\n","모든 설명이 끝이 났습니다! 이제 적당히 학습 함수를 정의하고 학습을 하면 됩니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"ylQqmx3R0J3X"},"source":["def run_epoch(data_iter, model, loss_compute):\n","    \"Standard Training and Logging Function\"\n","    start = time.time()\n","    total_tokens = 0\n","    total_loss = 0\n","    tokens = 0\n","    # data_iter를 만들 때 설정한 nbatches 만큼 루프를 돈다. 즉 1에폭\n","    for i, batch in enumerate(data_iter):\n","        out = model.forward(batch.src, batch.trg, \n","                            batch.src_mask, batch.trg_mask)\n","        \n","        # 여기서 loss_compute()는 SimpleLossCompute 임\n","        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n","        total_loss += loss\n","        total_tokens += batch.ntokens\n","        tokens += batch.ntokens\n","        \n","        if i % 50 == 1:\n","            elapsed = time.time() - start\n","            print(\"Epoch Step: %d, Loss: %f, Tokens per Sec: %f\" %\n","                    (i, loss / batch.ntokens, tokens / elapsed))\n","            start = time.time()\n","            tokens = 0\n","    return total_loss / total_tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NK_IZIRp1N0O","executionInfo":{"status":"ok","timestamp":1636516833980,"user_tz":-540,"elapsed":281966,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"a9e1fcbd-fb6e-4c17-d4ae-b5b541d7bff3"},"source":["# Train the simple copy task.\n","V = 11\n","criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n","model = make_model(V, V, N=2)\n","#                   model_size, factor, warmup, optimizer\n","model_opt = NoamOpt(model.src_embed[0].d_model, 1, 1200,\n","        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n","\n","for epoch in range(18):\n","    model.train()\n","    print(f'{epoch} epoch train')\n","    run_epoch(data_gen2(V, 30, 20), model, # 미니배치에 샘플 30개씩 20배치가 한에폭 \n","              SimpleLossCompute(model.generator, criterion, model_opt))\n","    print('eval')\n","    model.eval()\n","    eval_loss = run_epoch(data_gen2(V, 30, 5), model, # 미니배치에 샘플 30개씩 5배치가 한 에폭\n","                    SimpleLossCompute(model.generator, criterion, None))\n","    print('eval_loss:', eval_loss,'\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 epoch train\n","Epoch Step: 1, Loss: 2.899037, Tokens per Sec: 210.496277\n","eval\n","Epoch Step: 1, Loss: 2.265778, Tokens per Sec: 514.014282\n","eval_loss: tensor(2.2115, grad_fn=<DivBackward0>) \n","\n","1 epoch train\n","Epoch Step: 1, Loss: 2.333732, Tokens per Sec: 419.434052\n","eval\n","Epoch Step: 1, Loss: 2.035715, Tokens per Sec: 516.446472\n","eval_loss: tensor(2.0386, grad_fn=<DivBackward0>) \n","\n","2 epoch train\n","Epoch Step: 1, Loss: 2.167701, Tokens per Sec: 412.256683\n","eval\n","Epoch Step: 1, Loss: 1.881836, Tokens per Sec: 512.943665\n","eval_loss: tensor(1.9103, grad_fn=<DivBackward0>) \n","\n","3 epoch train\n","Epoch Step: 1, Loss: 2.069123, Tokens per Sec: 419.231018\n","eval\n","Epoch Step: 1, Loss: 1.850417, Tokens per Sec: 517.300476\n","eval_loss: tensor(1.8184, grad_fn=<DivBackward0>) \n","\n","4 epoch train\n","Epoch Step: 1, Loss: 2.078735, Tokens per Sec: 397.969116\n","eval\n","Epoch Step: 1, Loss: 1.755276, Tokens per Sec: 524.911316\n","eval_loss: tensor(1.7278, grad_fn=<DivBackward0>) \n","\n","5 epoch train\n","Epoch Step: 1, Loss: 2.029374, Tokens per Sec: 416.710968\n","eval\n","Epoch Step: 1, Loss: 1.571162, Tokens per Sec: 505.926727\n","eval_loss: tensor(1.5942, grad_fn=<DivBackward0>) \n","\n","6 epoch train\n","Epoch Step: 1, Loss: 1.775693, Tokens per Sec: 419.271454\n","eval\n","Epoch Step: 1, Loss: 1.534954, Tokens per Sec: 525.713135\n","eval_loss: tensor(1.5013, grad_fn=<DivBackward0>) \n","\n","7 epoch train\n","Epoch Step: 1, Loss: 1.771013, Tokens per Sec: 416.784576\n","eval\n","Epoch Step: 1, Loss: 1.503360, Tokens per Sec: 520.307434\n","eval_loss: tensor(1.4806, grad_fn=<DivBackward0>) \n","\n","8 epoch train\n","Epoch Step: 1, Loss: 1.663535, Tokens per Sec: 420.530945\n","eval\n","Epoch Step: 1, Loss: 1.283393, Tokens per Sec: 508.099396\n","eval_loss: tensor(1.2777, grad_fn=<DivBackward0>) \n","\n","9 epoch train\n","Epoch Step: 1, Loss: 1.491704, Tokens per Sec: 416.922150\n","eval\n","Epoch Step: 1, Loss: 1.156100, Tokens per Sec: 513.559937\n","eval_loss: tensor(1.1623, grad_fn=<DivBackward0>) \n","\n","10 epoch train\n","Epoch Step: 1, Loss: 1.273780, Tokens per Sec: 414.009247\n","eval\n","Epoch Step: 1, Loss: 1.057899, Tokens per Sec: 520.631042\n","eval_loss: tensor(1.0376, grad_fn=<DivBackward0>) \n","\n","11 epoch train\n","Epoch Step: 1, Loss: 1.345537, Tokens per Sec: 416.217438\n","eval\n","Epoch Step: 1, Loss: 1.030028, Tokens per Sec: 518.225952\n","eval_loss: tensor(1.0957, grad_fn=<DivBackward0>) \n","\n","12 epoch train\n","Epoch Step: 1, Loss: 1.337737, Tokens per Sec: 419.506073\n","eval\n","Epoch Step: 1, Loss: 0.926710, Tokens per Sec: 515.558350\n","eval_loss: tensor(0.9208, grad_fn=<DivBackward0>) \n","\n","13 epoch train\n","Epoch Step: 1, Loss: 1.186046, Tokens per Sec: 415.672577\n","eval\n","Epoch Step: 1, Loss: 0.690210, Tokens per Sec: 521.995117\n","eval_loss: tensor(0.8092, grad_fn=<DivBackward0>) \n","\n","14 epoch train\n","Epoch Step: 1, Loss: 0.863369, Tokens per Sec: 414.650177\n","eval\n","Epoch Step: 1, Loss: 0.636962, Tokens per Sec: 507.883820\n","eval_loss: tensor(0.5867, grad_fn=<DivBackward0>) \n","\n","15 epoch train\n","Epoch Step: 1, Loss: 0.743255, Tokens per Sec: 409.956757\n","eval\n","Epoch Step: 1, Loss: 0.382606, Tokens per Sec: 521.047974\n","eval_loss: tensor(0.3791, grad_fn=<DivBackward0>) \n","\n","16 epoch train\n","Epoch Step: 1, Loss: 0.585855, Tokens per Sec: 408.838745\n","eval\n","Epoch Step: 1, Loss: 0.263854, Tokens per Sec: 514.657593\n","eval_loss: tensor(0.2577, grad_fn=<DivBackward0>) \n","\n","17 epoch train\n","Epoch Step: 1, Loss: 0.558738, Tokens per Sec: 419.449036\n","eval\n","Epoch Step: 1, Loss: 0.356468, Tokens per Sec: 507.473694\n","eval_loss: tensor(0.3535, grad_fn=<DivBackward0>) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"RUrupippgGIZ"},"source":["## 예측"]},{"cell_type":"markdown","metadata":{"id":"T19efGH6gKZI"},"source":["트랜스포머를 학습 시킬 때 디코더에 정답이 모두 입력되고 출력도 한번에 나오게 됩니다. 하지만 학습이 끝나고 예측을 할 때는 그렇게 하지 않고 다음과 같은 순서로 하게 됩니다.\n","\n","1. 디코더에 [START] 토큰을 입력한다.\n","\n","2. [START] 토큰 다음에 나올 토큰을 트랜스포머가 예측한다.\n","\n","3. 예측된 [TKN1]을 붙여서 [START], [TKN1]을 디코더에 입력한다.\n","\n","4. 이런 식으로 계속 진행한다.\n","\n","이 과정에서 트랜스포머의 예측은 (nbatches, n_seq, vocab) 사이즈로 나오게 되는데 현재 스텝의 예측을 결정하기 위해 (nbatches, -1, vocab)에서 확률값이 가장 큰것을 고르게 됩니다. 이렇게 각 타임 스탭에서 적합한 단어를 고르는 전략을 탐욕 탐색greedy search라고 합니다. 하지만 이런 전략이 전체 시퀀스에 대해서 꼭 좋은 것은 아니라 빔서치같은 더 복잡한 방법을 사용하기도 합니다. 여기서는 가장 간단한 방법인 탐욕 탐색을 사용하였습니다."]},{"cell_type":"code","metadata":{"id":"JsKP-ZSX1QI8"},"source":["def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    memory = model.encode(src, src_mask)\n","\n","    # 시작은 [START]로 시작한다.\n","    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n","    \n","    # 생성할 시퀀스의 최대 길이만큰 순환하면서\n","    for i in range(max_len-1):\n","        print('ys.shape:', ys.shape)\n","        out = model.decode(\n","                    memory, src_mask, ys, \n","                    subsequent_mask(ys.size(1)).type_as(src.data)\n","                )\n","        print('out.shape:', out.shape)\n","        print('out[:, -1].shape:', out[:, -1].shape)\n","        \n","        # 마지막 타임스탭의 결과를 단어들로 바꾼다.\n","        prob = model.generator(out[:, -1])\n","        print('prob.shape:', prob.shape)\n","        \n","        # 가장 확률이 높은 단어를 선택한다.\n","\n","        _, next_word = torch.max(prob, dim = 1)\n","        next_word = next_word.data[0]\n","\n","        # 예측된 단어를 추가하고 루프 처음으로 돌아가 다시 ys를 디코더로 입력한다.\n","        ys = torch.cat([ys, \n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n","        print('\\n')\n","    return ys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0k0G9Z7W3hc6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636516833982,"user_tz":-540,"elapsed":15,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"337213bd-3f90-49bd-9b58-97daa4241ff9"},"source":["model.eval()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoder(\n","  (encoder): Encoder(\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): EncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (norm): LayerNorm()\n","  )\n","  (decoder): Decoder(\n","    (layers): ModuleList(\n","      (0): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): DecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (src_attn): MultiHeadedAttention(\n","          (linears): ModuleList(\n","            (0): Linear(in_features=512, out_features=512, bias=True)\n","            (1): Linear(in_features=512, out_features=512, bias=True)\n","            (2): Linear(in_features=512, out_features=512, bias=True)\n","            (3): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (sublayer): ModuleList(\n","          (0): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): SublayerConnection(\n","            (norm): LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (norm): LayerNorm()\n","  )\n","  (src_embed): Sequential(\n","    (0): Embeddings(\n","      (lut): Embedding(11, 512)\n","    )\n","    (1): PositionalEncoding(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (tgt_embed): Sequential(\n","    (0): Embeddings(\n","      (lut): Embedding(11, 512)\n","    )\n","    (1): PositionalEncoding(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (generator): Generator(\n","    (proj): Linear(in_features=512, out_features=11, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"18Za-Ur6fz1J"},"source":["아무 샘플 데이터나 무작위로 만들어 모델에 입력하고 입력 숫자들 중 뒤 다섯개가 1큰 숫자로 출력되는지 확인해봅시다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qw9mZ013v0Q","executionInfo":{"status":"ok","timestamp":1636516972359,"user_tz":-540,"elapsed":429,"user":{"displayName":"조준우","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0ZgKQRudtiTb-9MCS5s1P2RcfWz3M_eA-kdDe4g=s64","userId":"07581913480846489655"}},"outputId":"c8767a2f-2193-4a7c-925e-4b007135c5bf"},"source":["src = torch.LongTensor([[1, 3, 4, 5, 6,   8, 7, 2, 9,  7]])\n","# 정답                   1, 3, 4, 5, 6,   9, 8, 3, 10, 8\n","                         \n","\n","src_mask = torch.ones(1, 1, 10)\n","print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ys.shape: torch.Size([1, 1])\n","out.shape: torch.Size([1, 1, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 2])\n","out.shape: torch.Size([1, 2, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 3])\n","out.shape: torch.Size([1, 3, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 4])\n","out.shape: torch.Size([1, 4, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 5])\n","out.shape: torch.Size([1, 5, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 6])\n","out.shape: torch.Size([1, 6, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 7])\n","out.shape: torch.Size([1, 7, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 8])\n","out.shape: torch.Size([1, 8, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","ys.shape: torch.Size([1, 9])\n","out.shape: torch.Size([1, 9, 512])\n","out[:, -1].shape: torch.Size([1, 512])\n","prob.shape: torch.Size([1, 11])\n","\n","\n","tensor([[ 1,  3,  4,  5,  6,  9,  8,  3, 10,  8]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Hw06A7PTf7PR"},"source":["예상처럼 잘 출력되는 것을 확인할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"jX-2_n7pf-nY"},"source":["## 마무리\n","\n","처음 별것 아니라고 하고 시작한 글이 적고보니 엄청 복잡해진 듯한 느낌이 듭니다. 작성하는데 시간도 꽤 많이 걸린 듯 합니다. 부디 트랜스포머를 처음 공부하는 누군가에게 도움이 되길 바랍니다. 혹시 글에 대해서 이해하기 어려운 부분이나 수정이 필요한 부분이 있다면 언제든 연락주세요. "]}]}